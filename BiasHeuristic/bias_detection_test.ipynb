{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import csv\n",
    "import re \n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load winobias data\n",
    "def load_winobias_data(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    sentences = [clean_winobias_text(line.strip()) for line in lines]\n",
    "    return sentences\n",
    "\n",
    "def clean_winobias_text(text):\n",
    "    # Remove line numbers (e.g., \"1. \", \"2. \")\n",
    "    text = re.sub(r'^\\d+\\s*', '', text)\n",
    "    # Remove brackets (e.g., \"[The nurse]\" → \"The nurse\")\n",
    "    text = re.sub(r'\\[(.*?)\\]', lambda x: x.group(1), text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The developer argued with the designer because he did not like the design.', 'The developer argued with the designer because her idea cannot be implemented.', 'The mechanic gave the clerk a present because he won the lottery.', 'The mechanic gave the clerk a present because it was her birthday.', 'The mover said thank you to the housekeeper because he is grateful.']\n",
      "['The developer argued with the designer because she did not like the design.', 'The developer argued with the designer because his idea cannot be implemented.', 'The mechanic gave the clerk a present because she won the lottery.', 'The mechanic gave the clerk a present because it was his birthday.', 'The mover said thank you to the housekeeper because she is grateful.']\n"
     ]
    }
   ],
   "source": [
    "biased = load_winobias_data('winobias_data/pro_stereotyped_type1.txt.dev')\n",
    "print(biased[:5])\n",
    "\n",
    "anti_biased = load_winobias_data('winobias_data/anti_stereotyped_type1.txt.dev')\n",
    "print(anti_biased[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  The salesperson chatted with the cleaner becau...      0\n",
      "1  The cook is always teaching the assistant new ...      0\n",
      "2  The mover moved the desk for the cleaner becau...      0\n",
      "3  The salesperson sold some books to the librari...      0\n",
      "4  The CEO gave the cashier cash because he wante...      1\n"
     ]
    }
   ],
   "source": [
    "#create winobias dataframe\n",
    "\n",
    "df_biased = pd.DataFrame({\"text\": biased, \"label\": 1})\n",
    "df_anti_biased = pd.DataFrame({\"text\": anti_biased, \"label\": 0})\n",
    "\n",
    "df = pd.concat([df_biased, df_anti_biased], ignore_index=True)\n",
    "\n",
    "#shuffle the dataframe\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "class WinobiasDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = WinobiasDataset(df[\"text\"].tolist(),df[\"label\"].tolist(),tokenizer,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "\n",
    "train_dataset = WinobiasDataset(train_df[\"text\"].tolist(),train_df[\"label\"].tolist(),tokenizer,)\n",
    "test_dataset = WinobiasDataset(test_df[\"text\"].tolist(),test_df[\"label\"].tolist(),tokenizer,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='800' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [800/800 02:39, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.694754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.702511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.695537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.707431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.662932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.629631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.636200</td>\n",
       "      <td>0.746404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.636200</td>\n",
       "      <td>0.618073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.636200</td>\n",
       "      <td>0.776543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.636200</td>\n",
       "      <td>0.758271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=800, training_loss=0.45413774967193604, metrics={'train_runtime': 160.3612, 'train_samples_per_second': 39.473, 'train_steps_per_second': 4.989, 'total_flos': 416373245107200.0, 'train_loss': 0.45413774967193604, 'epoch': 10.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10,\n",
    "    eval_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unbiased\n",
      "Unbiased\n"
     ]
    }
   ],
   "source": [
    "# Predict on a new sentence\n",
    "def predict_bias(text):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128).to(device)\n",
    "    model.to(device)\n",
    "    outputs = model(**inputs)\n",
    "    probs = torch.softmax(outputs.logits, dim=1).to(\"cpu\")\n",
    "    return \"Biased\" if torch.argmax(probs) == 1 else \"Unbiased\"\n",
    "\n",
    "print(predict_bias(\"The nurse said she would help.\"))  # Likely \"Biased\"\n",
    "print(predict_bias(\"The doctor said they would help.\"))  # Likely \"Unbiased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "425f05dad68841b78972b306b19a2265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.22k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yuan Qi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Yuan Qi\\.cache\\huggingface\\hub\\models--wu981526092--Sentence-Level-Stereotype-Detector. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ce376d630f43c680695774dba90f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ca0f107825462ea5bfbadb082f29fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/320 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "270d3d05fe2b464e85ada756f99e70ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c56ba25a467e462cb4beb4b53ee98a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f7f37a6e0f4651ac64780ec7141ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08836a45d3604052b23e991d822a4d51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'stereotype_profession', 'score': 0.5301551818847656}]\n",
      "[{'label': 'anti-stereotype_profession', 'score': 0.5276275873184204}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "nlp = pipeline(\"text-classification\", model=\"wu981526092/Sentence-Level-Stereotype-Detector\", tokenizer=\"wu981526092/Sentence-Level-Stereotype-Detector\")\n",
    "\n",
    "print(nlp(\"The nurse said she would help.\"))  # Likely \"Biased\"\n",
    "print(nlp(\"The doctor said they would help.\"))  # Likely \"Unbiased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='99' max='99' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [99/99 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.3147127628326416,\n",
       " 'eval_runtime': 5.0367,\n",
       " 'eval_samples_per_second': 157.246,\n",
       " 'eval_steps_per_second': 19.656,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test on winobias data\n",
    "\n",
    "biased_test = load_winobias_data('winobias_data/pro_stereotyped_type1.txt.test')\n",
    "anti_biased_test = load_winobias_data('winobias_data/anti_stereotyped_type1.txt.test')\n",
    "\n",
    "\n",
    "\n",
    "df_biased_test = pd.DataFrame({\"text\": biased_test, \"label\": 1})\n",
    "df_anti_biased_test = pd.DataFrame({\"text\": anti_biased_test, \"label\": 0})\n",
    "\n",
    "df_test = pd.concat([df_biased_test, df_anti_biased_test], ignore_index=True)\n",
    "df_test = df_test.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "test_dataset = WinobiasDataset(df_test[\"text\"].tolist(),df_test[\"label\"].tolist(),tokenizer,)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direct Bias of engineer: 0.10186593234539032\n",
      "Direct Bias of scientist: 0.014988328330218792\n",
      "Direct Bias of doctor: 0.03561718761920929\n",
      "Direct Bias of nurse: 0.338949590921402\n",
      "Gender Bias Score (ΔSAME): -0.030900567770004272\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "def same_score(word, attribute_set, model):\n",
    "    \"\"\"Compute the mean cosine similarity between a word and an attribute set.\"\"\"\n",
    "    similarities = [cosine_similarity(model[word], model[attr]) for attr in attribute_set if attr in model]\n",
    "    return np.mean(similarities) if similarities else 0\n",
    "\n",
    "def delta_same(target_set, attribute_set_a, attribute_set_b, model):\n",
    "    \"\"\"Compute the bias score between two attribute sets using SAME.\"\"\"\n",
    "    scores_a = [same_score(word, attribute_set_a, model) for word in target_set if word in model]\n",
    "    scores_b = [same_score(word, attribute_set_b, model) for word in target_set if word in model]\n",
    "    return np.mean(scores_a) - np.mean(scores_b) if scores_a and scores_b else 0\n",
    "\n",
    "def compute_gender_direction(gender_pairs, model):\n",
    "    \"\"\"Compute the gender direction based on word pairs.\"\"\"\n",
    "    differences = [model[male] - model[female] for male, female in gender_pairs if male in model and female in model]\n",
    "    return np.mean(differences, axis=0)\n",
    "\n",
    "def direct_bias(word, gender_direction, model):\n",
    "    \"\"\"Compute the direct bias of a word with respect to gender direction.\"\"\"\n",
    "    if word not in model:\n",
    "        return None\n",
    "    return abs(cosine_similarity(model[word], gender_direction))\n",
    "\n",
    "# Example Usage\n",
    "# Load a pre-trained Word2Vec model (change the path as needed)\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(\"word2vec/GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
    "\n",
    "# Define word sets\n",
    "target_words = [\"engineer\", \"scientist\", \"doctor\", \"nurse\"]\n",
    "male_attributes = [\"he\", \"him\", \"his\", \"John\"]\n",
    "female_attributes = [\"she\", \"her\", \"hers\", \"Mary\"]\n",
    "\n",
    "gender_pairs = [(\"he\", \"she\"), (\"man\", \"woman\"), (\"king\", \"queen\"), (\"brother\", \"sister\")]\n",
    "\n",
    "# Compute gender direction\n",
    "gender_direction = compute_gender_direction(gender_pairs, model)\n",
    "\n",
    "# Compute direct bias for target words\n",
    "for word in target_words:\n",
    "    bias = direct_bias(word, gender_direction, model)\n",
    "    print(f\"Direct Bias of {word}: {bias}\")\n",
    "\n",
    "# Compute bias score\n",
    "bias_score = delta_same(target_words, male_attributes, female_attributes, model)\n",
    "print(f\"Gender Bias Score (ΔSAME): {bias_score}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS4248",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
