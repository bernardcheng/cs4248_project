{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import statements\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils.ppmi import build_ppmi\n",
    "from utils.retrofit import sharded_retrofit, join_shards\n",
    "from utils.formats import load_hdf, save_hdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test heuristics (Refactored for use with PPMI)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"Compute cosine similarity between two vectors.\"\"\"\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "def same_score(word, attribute_set, ppmi_df):\n",
    "    \"\"\"Compute the mean cosine similarity between a word and an attribute set.\"\"\"\n",
    "    if word not in ppmi_df.index:\n",
    "        return 0\n",
    "    word_vec = ppmi_df.loc[word].values\n",
    "    similarities = [\n",
    "        cosine_similarity(word_vec, ppmi_df.loc[attr].values)\n",
    "        for attr in attribute_set if attr in ppmi_df.index\n",
    "    ]\n",
    "    return np.mean(similarities) if similarities else 0\n",
    "\n",
    "def delta_same(target_set, attribute_set_a, attribute_set_b, ppmi_df):\n",
    "    \"\"\"Compute the bias score between two attribute sets using SAME.\"\"\"\n",
    "    scores_a = [same_score(word, attribute_set_a, ppmi_df) for word in target_set if word in ppmi_df.index]\n",
    "    scores_b = [same_score(word, attribute_set_b, ppmi_df) for word in target_set if word in ppmi_df.index]\n",
    "    # print(scores_a)\n",
    "    # print(scores_b)\n",
    "    return np.mean(scores_a) - np.mean(scores_b) if scores_a and scores_b else 0\n",
    "\n",
    "def compute_gender_direction(gender_pairs, gender_pairs2, ppmi_df):\n",
    "    \"\"\"Compute the gender direction based on word pairs.\"\"\"\n",
    "    differences = []\n",
    "       # Try primary gender pairs first (c/en/man, c/en/woman)\n",
    "    for male, female in gender_pairs:\n",
    "        if male in ppmi_df.index and female in ppmi_df.index:\n",
    "            diff = ppmi_df.loc[male].values - ppmi_df.loc[female].values\n",
    "            differences.append(diff)\n",
    "        else:\n",
    "            print(f\"Skipping pair ({male}, {female}) — one or both not in PPMI (primary).\")\n",
    "\n",
    "    # If none found, try secondary gender pairs (c/en/men, c/en/women)\n",
    "    if not differences:\n",
    "        for male, female in gender_pairs2:\n",
    "            if male in ppmi_df.index and female in ppmi_df.index:\n",
    "                diff = ppmi_df.loc[male].values - ppmi_df.loc[female].values\n",
    "                differences.append(diff)\n",
    "            else:\n",
    "                print(f\"Skipping pair ({male}, {female}) — one or both not in PPMI (fallback).\")\n",
    "    \n",
    "    if not differences:\n",
    "        raise ValueError(\"No valid gender pairs found in PPMI.\")\n",
    "\n",
    "    return np.mean(differences, axis=0)\n",
    "\n",
    "def direct_bias(word, gender_direction, ppmi_df):\n",
    "    \"\"\"Compute the direct bias of a word with respect to gender direction.\"\"\"\n",
    "    if word not in ppmi_df.index:\n",
    "        return 0\n",
    "    return abs(cosine_similarity(ppmi_df.loc[word].values, gender_direction))\n",
    "\n",
    "def direct_bias_wordlist(word_list, gender_dir, ppmi_df, label, output_path):\n",
    "    results = []\n",
    "    for word in word_list:\n",
    "        if word in ppmi_df.index:\n",
    "            bias = direct_bias(word, gender_dir, ppmi_df)\n",
    "            results.append({\"word\": word, \"bias\": bias, \"group\": label})\n",
    "        else:\n",
    "            results.append({\"word\": word, \"bias\": None, \"group\": None})  # Word not in PPMI\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_path, index=False)\n",
    "    return df\n",
    "\n",
    "def to_conceptnet_uri(word):\n",
    "    return \"/c/en/\" + word.strip().lower().replace(\" \", \"_\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>260</th>\n",
       "      <th>261</th>\n",
       "      <th>262</th>\n",
       "      <th>263</th>\n",
       "      <th>264</th>\n",
       "      <th>265</th>\n",
       "      <th>266</th>\n",
       "      <th>267</th>\n",
       "      <th>268</th>\n",
       "      <th>269</th>\n",
       "      <th>270</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "      <th>280</th>\n",
       "      <th>281</th>\n",
       "      <th>282</th>\n",
       "      <th>283</th>\n",
       "      <th>284</th>\n",
       "      <th>285</th>\n",
       "      <th>286</th>\n",
       "      <th>287</th>\n",
       "      <th>288</th>\n",
       "      <th>289</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/c/en/help_child</th>\n",
       "      <td>5.379521e-16</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>5.409838e-06</td>\n",
       "      <td>4.022300e-15</td>\n",
       "      <td>-1.130818e-15</td>\n",
       "      <td>5.853341e-17</td>\n",
       "      <td>9.179294e-17</td>\n",
       "      <td>-4.842451e-16</td>\n",
       "      <td>1.788475e-15</td>\n",
       "      <td>2.421133e-15</td>\n",
       "      <td>-2.488438e-16</td>\n",
       "      <td>-1.801727e-16</td>\n",
       "      <td>4.414657e-16</td>\n",
       "      <td>1.054125e-16</td>\n",
       "      <td>-9.243286e-16</td>\n",
       "      <td>-1.304739e-15</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-5.219719e-13</td>\n",
       "      <td>-6.876059e-13</td>\n",
       "      <td>3.019614e-16</td>\n",
       "      <td>2.404599e-16</td>\n",
       "      <td>-7.063852e-17</td>\n",
       "      <td>1.688280e-15</td>\n",
       "      <td>6.626313e-16</td>\n",
       "      <td>1.491595e-16</td>\n",
       "      <td>-5.326894e-17</td>\n",
       "      <td>1.248755e-16</td>\n",
       "      <td>5.099102e-16</td>\n",
       "      <td>1.274973e-15</td>\n",
       "      <td>5.814638e-17</td>\n",
       "      <td>9.278852e-16</td>\n",
       "      <td>5.973974e-16</td>\n",
       "      <td>9.020796e-16</td>\n",
       "      <td>2.163206e-16</td>\n",
       "      <td>-2.507475e-16</td>\n",
       "      <td>-1.995420e-16</td>\n",
       "      <td>-1.024341e-16</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006798</td>\n",
       "      <td>-0.067762</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.117447</td>\n",
       "      <td>0.028399</td>\n",
       "      <td>0.107606</td>\n",
       "      <td>0.028905</td>\n",
       "      <td>0.050568</td>\n",
       "      <td>0.041218</td>\n",
       "      <td>-0.076765</td>\n",
       "      <td>-0.010367</td>\n",
       "      <td>-0.001069</td>\n",
       "      <td>-0.015993</td>\n",
       "      <td>-0.019940</td>\n",
       "      <td>0.120977</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>-0.173459</td>\n",
       "      <td>0.001825</td>\n",
       "      <td>0.003134</td>\n",
       "      <td>-0.037326</td>\n",
       "      <td>0.066751</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-4.064832e-07</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>-0.002607</td>\n",
       "      <td>-0.059551</td>\n",
       "      <td>0.004967</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>-0.004004</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>-0.025836</td>\n",
       "      <td>-0.041820</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>-0.000221</td>\n",
       "      <td>-0.000418</td>\n",
       "      <td>-0.005307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/c/en/adult</th>\n",
       "      <td>-5.947637e-16</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>4.268783e-06</td>\n",
       "      <td>4.570441e-15</td>\n",
       "      <td>-2.390922e-15</td>\n",
       "      <td>9.802262e-16</td>\n",
       "      <td>-1.523202e-15</td>\n",
       "      <td>-9.785777e-16</td>\n",
       "      <td>2.679285e-15</td>\n",
       "      <td>2.011361e-15</td>\n",
       "      <td>4.595419e-16</td>\n",
       "      <td>2.993147e-16</td>\n",
       "      <td>-1.408068e-15</td>\n",
       "      <td>-4.691903e-18</td>\n",
       "      <td>-6.144958e-17</td>\n",
       "      <td>-4.335018e-16</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-6.948072e-13</td>\n",
       "      <td>-9.187887e-13</td>\n",
       "      <td>6.142368e-16</td>\n",
       "      <td>-8.152512e-16</td>\n",
       "      <td>5.585749e-16</td>\n",
       "      <td>3.476900e-15</td>\n",
       "      <td>1.395646e-15</td>\n",
       "      <td>-3.802114e-16</td>\n",
       "      <td>5.134670e-16</td>\n",
       "      <td>1.751211e-16</td>\n",
       "      <td>1.616799e-15</td>\n",
       "      <td>2.437179e-15</td>\n",
       "      <td>4.847232e-16</td>\n",
       "      <td>1.230230e-15</td>\n",
       "      <td>1.860467e-15</td>\n",
       "      <td>2.401617e-15</td>\n",
       "      <td>3.251105e-16</td>\n",
       "      <td>-6.257412e-16</td>\n",
       "      <td>-5.789931e-16</td>\n",
       "      <td>9.628434e-16</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028524</td>\n",
       "      <td>-0.286402</td>\n",
       "      <td>0.002562</td>\n",
       "      <td>0.500944</td>\n",
       "      <td>0.123374</td>\n",
       "      <td>0.468505</td>\n",
       "      <td>0.126112</td>\n",
       "      <td>0.221050</td>\n",
       "      <td>0.185074</td>\n",
       "      <td>-0.354480</td>\n",
       "      <td>-0.047849</td>\n",
       "      <td>-0.004924</td>\n",
       "      <td>-0.070011</td>\n",
       "      <td>-0.092340</td>\n",
       "      <td>0.568099</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>-0.825742</td>\n",
       "      <td>0.008801</td>\n",
       "      <td>0.015262</td>\n",
       "      <td>-0.181795</td>\n",
       "      <td>0.332760</td>\n",
       "      <td>0.002741</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-1.303094e-06</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.004753</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>-0.015994</td>\n",
       "      <td>-0.443037</td>\n",
       "      <td>0.036631</td>\n",
       "      <td>0.018061</td>\n",
       "      <td>-0.030400</td>\n",
       "      <td>0.001878</td>\n",
       "      <td>-0.202185</td>\n",
       "      <td>-0.345947</td>\n",
       "      <td>0.045245</td>\n",
       "      <td>0.012511</td>\n",
       "      <td>-0.001947</td>\n",
       "      <td>-0.003833</td>\n",
       "      <td>-0.052088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/c/en/man</th>\n",
       "      <td>3.273319e-16</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-8.463431e-07</td>\n",
       "      <td>-8.760094e-16</td>\n",
       "      <td>1.120815e-15</td>\n",
       "      <td>-7.305838e-16</td>\n",
       "      <td>-1.708740e-15</td>\n",
       "      <td>5.022793e-16</td>\n",
       "      <td>-7.084706e-16</td>\n",
       "      <td>1.520039e-15</td>\n",
       "      <td>4.691970e-16</td>\n",
       "      <td>-1.022493e-15</td>\n",
       "      <td>-1.697470e-15</td>\n",
       "      <td>-1.314639e-16</td>\n",
       "      <td>5.744029e-16</td>\n",
       "      <td>4.268142e-17</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-1.076487e-13</td>\n",
       "      <td>-1.528285e-13</td>\n",
       "      <td>7.064738e-16</td>\n",
       "      <td>-4.197134e-16</td>\n",
       "      <td>1.512642e-15</td>\n",
       "      <td>5.542464e-15</td>\n",
       "      <td>1.446664e-15</td>\n",
       "      <td>9.524747e-16</td>\n",
       "      <td>-7.140052e-16</td>\n",
       "      <td>-2.909484e-16</td>\n",
       "      <td>-6.448216e-16</td>\n",
       "      <td>-1.274253e-15</td>\n",
       "      <td>2.495376e-16</td>\n",
       "      <td>-1.151763e-15</td>\n",
       "      <td>-1.749162e-16</td>\n",
       "      <td>-1.184899e-15</td>\n",
       "      <td>2.050840e-16</td>\n",
       "      <td>8.106973e-16</td>\n",
       "      <td>1.033045e-15</td>\n",
       "      <td>5.861342e-18</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087890</td>\n",
       "      <td>-1.169623</td>\n",
       "      <td>-0.223616</td>\n",
       "      <td>1.733351</td>\n",
       "      <td>0.840813</td>\n",
       "      <td>0.657052</td>\n",
       "      <td>0.164061</td>\n",
       "      <td>0.804747</td>\n",
       "      <td>0.482572</td>\n",
       "      <td>-1.194194</td>\n",
       "      <td>-0.207881</td>\n",
       "      <td>-0.020511</td>\n",
       "      <td>0.027010</td>\n",
       "      <td>-0.180812</td>\n",
       "      <td>1.282072</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>-1.782536</td>\n",
       "      <td>0.022816</td>\n",
       "      <td>0.012983</td>\n",
       "      <td>-0.140894</td>\n",
       "      <td>0.790048</td>\n",
       "      <td>0.010274</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>1.116948e-04</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>0.037078</td>\n",
       "      <td>-0.000967</td>\n",
       "      <td>0.006626</td>\n",
       "      <td>-0.902754</td>\n",
       "      <td>-0.313210</td>\n",
       "      <td>0.155744</td>\n",
       "      <td>-0.142276</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>-0.754510</td>\n",
       "      <td>-0.660803</td>\n",
       "      <td>0.098269</td>\n",
       "      <td>0.024405</td>\n",
       "      <td>-0.007568</td>\n",
       "      <td>0.039280</td>\n",
       "      <td>-0.059049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/c/en/sign_contract</th>\n",
       "      <td>-8.984204e-17</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>5.824575e-06</td>\n",
       "      <td>4.030767e-15</td>\n",
       "      <td>-1.090103e-15</td>\n",
       "      <td>-1.204847e-16</td>\n",
       "      <td>3.375345e-16</td>\n",
       "      <td>-3.556234e-16</td>\n",
       "      <td>1.765867e-15</td>\n",
       "      <td>2.291911e-15</td>\n",
       "      <td>-3.378808e-16</td>\n",
       "      <td>-9.213008e-17</td>\n",
       "      <td>6.516395e-16</td>\n",
       "      <td>4.373117e-16</td>\n",
       "      <td>-1.143419e-15</td>\n",
       "      <td>-1.284033e-15</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-4.885095e-13</td>\n",
       "      <td>-6.432432e-13</td>\n",
       "      <td>6.475981e-16</td>\n",
       "      <td>1.931887e-16</td>\n",
       "      <td>3.096021e-16</td>\n",
       "      <td>7.561739e-16</td>\n",
       "      <td>1.647932e-16</td>\n",
       "      <td>6.073674e-17</td>\n",
       "      <td>1.248562e-16</td>\n",
       "      <td>-2.244604e-16</td>\n",
       "      <td>4.071271e-16</td>\n",
       "      <td>4.590920e-16</td>\n",
       "      <td>2.190544e-17</td>\n",
       "      <td>5.391275e-16</td>\n",
       "      <td>4.461709e-16</td>\n",
       "      <td>7.747315e-16</td>\n",
       "      <td>2.068224e-16</td>\n",
       "      <td>5.935970e-17</td>\n",
       "      <td>5.277909e-17</td>\n",
       "      <td>5.180302e-16</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>-0.000428</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006695</td>\n",
       "      <td>-0.066780</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.115607</td>\n",
       "      <td>0.027978</td>\n",
       "      <td>0.106050</td>\n",
       "      <td>0.028479</td>\n",
       "      <td>0.049844</td>\n",
       "      <td>0.040521</td>\n",
       "      <td>-0.075000</td>\n",
       "      <td>-0.010153</td>\n",
       "      <td>-0.001048</td>\n",
       "      <td>-0.015964</td>\n",
       "      <td>-0.019645</td>\n",
       "      <td>0.119336</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>-0.170995</td>\n",
       "      <td>0.001797</td>\n",
       "      <td>0.003085</td>\n",
       "      <td>-0.036742</td>\n",
       "      <td>0.065712</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-4.508414e-07</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>-0.002568</td>\n",
       "      <td>-0.058443</td>\n",
       "      <td>0.004904</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>-0.003947</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>-0.025528</td>\n",
       "      <td>-0.041064</td>\n",
       "      <td>0.005288</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>-0.000217</td>\n",
       "      <td>-0.000418</td>\n",
       "      <td>-0.005244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/c/en/dress_herself</th>\n",
       "      <td>-8.856595e-17</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>5.824575e-06</td>\n",
       "      <td>4.199817e-15</td>\n",
       "      <td>-1.090356e-15</td>\n",
       "      <td>1.005326e-16</td>\n",
       "      <td>1.788506e-16</td>\n",
       "      <td>4.788353e-17</td>\n",
       "      <td>1.832971e-15</td>\n",
       "      <td>2.359555e-15</td>\n",
       "      <td>-7.076026e-16</td>\n",
       "      <td>-3.601943e-17</td>\n",
       "      <td>8.369200e-16</td>\n",
       "      <td>3.974509e-16</td>\n",
       "      <td>-1.328338e-15</td>\n",
       "      <td>-1.425896e-15</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-4.882903e-13</td>\n",
       "      <td>-6.431086e-13</td>\n",
       "      <td>5.646216e-16</td>\n",
       "      <td>2.435448e-16</td>\n",
       "      <td>2.320973e-16</td>\n",
       "      <td>8.184080e-16</td>\n",
       "      <td>2.326295e-16</td>\n",
       "      <td>-1.060871e-16</td>\n",
       "      <td>1.774710e-16</td>\n",
       "      <td>-4.034883e-17</td>\n",
       "      <td>4.200285e-16</td>\n",
       "      <td>6.352547e-16</td>\n",
       "      <td>-1.573358e-17</td>\n",
       "      <td>6.188916e-16</td>\n",
       "      <td>3.832302e-16</td>\n",
       "      <td>6.544357e-16</td>\n",
       "      <td>2.997770e-16</td>\n",
       "      <td>7.610556e-17</td>\n",
       "      <td>-1.174043e-16</td>\n",
       "      <td>3.359658e-16</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>-0.000428</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006695</td>\n",
       "      <td>-0.066780</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.115607</td>\n",
       "      <td>0.027978</td>\n",
       "      <td>0.106050</td>\n",
       "      <td>0.028479</td>\n",
       "      <td>0.049844</td>\n",
       "      <td>0.040521</td>\n",
       "      <td>-0.075000</td>\n",
       "      <td>-0.010153</td>\n",
       "      <td>-0.001048</td>\n",
       "      <td>-0.015964</td>\n",
       "      <td>-0.019645</td>\n",
       "      <td>0.119336</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>-0.170995</td>\n",
       "      <td>0.001797</td>\n",
       "      <td>0.003085</td>\n",
       "      <td>-0.036742</td>\n",
       "      <td>0.065712</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-4.508414e-07</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>-0.002568</td>\n",
       "      <td>-0.058443</td>\n",
       "      <td>0.004904</td>\n",
       "      <td>0.002268</td>\n",
       "      <td>-0.003947</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>-0.025528</td>\n",
       "      <td>-0.041064</td>\n",
       "      <td>0.005288</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>-0.000217</td>\n",
       "      <td>-0.000418</td>\n",
       "      <td>-0.005244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0         1    ...       298       299\n",
       "/c/en/help_child     5.379521e-16 -0.000013  ... -0.000418 -0.005307\n",
       "/c/en/adult         -5.947637e-16 -0.000030  ... -0.003833 -0.052088\n",
       "/c/en/man            3.273319e-16 -0.000016  ...  0.039280 -0.059049\n",
       "/c/en/sign_contract -8.984204e-17 -0.000009  ... -0.000418 -0.005244\n",
       "/c/en/dress_herself -8.856595e-17 -0.000009  ... -0.000418 -0.005244\n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Variable declarations\n",
    "ppmi_df = pd.read_hdf('data/conceptnet_api/hdf/test.hdf')\n",
    "ppmi_df.head()\n",
    "# print(ppmi_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading from csv\n",
    "female_df = pd.read_csv(\"data/gendered/gender_f_cleaned.csv\", header=None)\n",
    "male_df = pd.read_csv(\"data/gendered/gender_m_cleaned.csv\", header=None)\n",
    "neutral_df = pd.read_csv(\"data/gender_neutral/gender_n_cleaned.csv\", header=None)\n",
    "\n",
    "female_words_target = female_df[0].dropna().apply(to_conceptnet_uri).tolist()\n",
    "male_words_target = male_df[0].dropna().apply(to_conceptnet_uri).tolist()\n",
    "neutral_words_target = neutral_df[0].dropna().apply(to_conceptnet_uri).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender direction (preview): [-5.22156241e-16 -9.12611510e-05  2.26672453e-05 -5.91807779e-06\n",
      " -9.24422121e-16]\n",
      "SAME bias score neutral: 0.020677905963184078\n",
      "SAME bias score male: 0.26932468067546717\n",
      "SAME bias score female: -0.5780757625079354\n",
      "Direct bias for '/c/en/doctor': 0.6830964319194655\n"
     ]
    }
   ],
   "source": [
    "### Calculation of heuristics (Benchmark set as this has no edits done)\n",
    "gender_pairs = [(\"/c/en/man\", \"/c/en/woman\")]\n",
    "gender_pairs2 = [(\"/c/en/men\", \"/c/en/women\")]\n",
    "attribute_set_a = [\"/c/en/he\", \"/c/en/him\", \"/c/en/his\"]\n",
    "attribute_set_b = [\"/c/en/she\", \"/c/en/her\", \"/c/en/hers\"]\n",
    "\n",
    "# --- Run calculations ---\n",
    "gender_dir = compute_gender_direction(gender_pairs, gender_pairs2, ppmi_df)\n",
    "# SAME bias calculations\n",
    "bias_same_neutral = delta_same(neutral_words_target, attribute_set_a, attribute_set_b, ppmi_df)\n",
    "bias_same_male = delta_same(male_words_target, attribute_set_a, attribute_set_b, ppmi_df)\n",
    "bias_same_female = delta_same(female_words_target, attribute_set_a, attribute_set_b, ppmi_df)\n",
    "# Direct bias calculations\n",
    "bias_direct = direct_bias(\"/c/en/doctor\", gender_dir, ppmi_df)\n",
    "# Saving direct bias to csv \n",
    "output_dir = \"data/heuristic/directBias/benchmark\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "female_biases = direct_bias_wordlist(female_words_target, gender_dir, ppmi_df, \"female\", \"data/heuristic/directBias/benchmark/female_bias.csv\")\n",
    "male_biases = direct_bias_wordlist(male_words_target, gender_dir, ppmi_df, \"male\", \"data/heuristic/directBias/benchmark/male_bias.csv\")\n",
    "neutral_biases = direct_bias_wordlist(neutral_words_target, gender_dir, ppmi_df, \"neutral\", \"data/heuristic/directBias/benchmark/neutral_bias.csv\")\n",
    "\n",
    "print(\"Gender direction (preview):\", gender_dir[:5])\n",
    "print(\"SAME bias score neutral:\", bias_same_neutral)\n",
    "print(\"SAME bias score male:\", bias_same_male)\n",
    "print(\"SAME bias score female:\", bias_same_female)\n",
    "print(\"Direct bias for '/c/en/doctor':\", bias_direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender direction (preview): [-7.2579083e-17 -1.9953368e-05 -1.9663707e-06 -1.4625811e-05\n",
      " -4.0829847e-17]\n",
      "SAME bias score neutral: nan\n",
      "SAME bias score male: nan\n",
      "SAME bias score female: -0.42026755\n",
      "Direct bias for '/c/en/doctor': 0.5245204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_297568\\2453461954.py:8: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n"
     ]
    }
   ],
   "source": [
    "### Hypothesis 1: Does incorporating graph structure into word embeddings reduce bias?\n",
    "sharded_retrofit(\n",
    "    dense_hdf_filename=\"data/conceptnet_api/hdf/test.hdf\",\n",
    "    conceptnet_filename=\"data/conceptnet_api/csv/edge_extract.csv\",\n",
    "    output_filename=\"data/conceptnet_api/retrofit/test_retrofitted\"\n",
    ")\n",
    "\n",
    "join_shards(output_filename=\"data/conceptnet_api/retrofit/test_retrofitted\", nshards=8, sort=False)\n",
    "\n",
    "retrofitted_ppmi = pd.read_hdf(\"data/conceptnet_api/retrofit/test_retrofitted\")\n",
    "\n",
    "gender_pairs = [(\"/c/en/man\", \"/c/en/woman\")]\n",
    "gender_pairs2 = [(\"/c/en/men\", \"/c/en/women\")]\n",
    "attribute_set_a = [\"/c/en/he\", \"/c/en/him\", \"/c/en/his\"]\n",
    "attribute_set_b = [\"/c/en/she\", \"/c/en/her\", \"/c/en/hers\"]\n",
    "\n",
    "# --- Run calculations ---\n",
    "gender_dir = compute_gender_direction(gender_pairs, gender_pairs2, retrofitted_ppmi)\n",
    "# SAME bias calculations\n",
    "bias_same_neutral = delta_same(neutral_words_target, attribute_set_a, attribute_set_b, retrofitted_ppmi)\n",
    "bias_same_male = delta_same(male_words_target, attribute_set_a, attribute_set_b, retrofitted_ppmi)\n",
    "bias_same_female = delta_same(female_words_target, attribute_set_a, attribute_set_b, retrofitted_ppmi)\n",
    "# Direct bias calculations\n",
    "bias_direct = direct_bias(\"/c/en/doctor\", gender_dir, retrofitted_ppmi)\n",
    "# Saving direct bias to csv \n",
    "output_dir = \"data/heuristic/directBias/hypothesis1\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "female_biases = direct_bias_wordlist(female_words_target, gender_dir, retrofitted_ppmi, \"female\", \"data/heuristic/directBias/hypothesis1/female_bias.csv\")\n",
    "male_biases = direct_bias_wordlist(male_words_target, gender_dir, retrofitted_ppmi, \"male\", \"data/heuristic/directBias/hypothesis1/male_bias.csv\")\n",
    "neutral_biases = direct_bias_wordlist(neutral_words_target, gender_dir, retrofitted_ppmi, \"neutral\", \"data/heuristic/directBias/hypothesis1/neutral_bias.csv\")\n",
    "\n",
    "print(\"Gender direction (preview):\", gender_dir[:5])\n",
    "print(\"SAME bias score neutral:\", bias_same_neutral)\n",
    "print(\"SAME bias score male:\", bias_same_male)\n",
    "print(\"SAME bias score female:\", bias_same_female)\n",
    "print(\"Direct bias for '/c/en/doctor':\", bias_direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender direction (preview): [-1.34992619e-15 -3.14803562e-15 -2.66589376e-05 -2.18844882e-05\n",
      "  3.24484993e-06]\n",
      "SAME bias score neutral: 0.020635123338666708\n",
      "SAME bias score male: 0.2689158195800159\n",
      "SAME bias score female: -0.5813703747456964\n",
      "Direct bias for '/c/en/doctor': 0.6820667020592693\n"
     ]
    }
   ],
   "source": [
    "#### Code above was functionality testing, code below demonstrates actual work tried\n",
    "# Variation 1: Small dataset + Filter (Antonyms)\n",
    "# First have to edit scraper for filtering.\n",
    "df = pd.read_csv(\"data/conceptnet_api/csv/edge_extractVar1.csv\")\n",
    "# print(df.shape)\n",
    "# print(df['weight'].describe())\n",
    "# df.head(3)\n",
    "ppmi_df_var1 = build_ppmi(conceptnet_filename=\"data/conceptnet_api/csv/edge_extractVar1.csv\", ndim=300)\n",
    "save_hdf(ppmi_df_var1, filename='data/conceptnet_api/hdf/testVar1.hdf')\n",
    "\n",
    "gender_pairs = [(\"/c/en/man\", \"/c/en/woman\")]\n",
    "gender_pairs2 = [(\"/c/en/men\", \"/c/en/women\")]\n",
    "attribute_set_a = [\"/c/en/he\", \"/c/en/him\", \"/c/en/his\"]\n",
    "attribute_set_b = [\"/c/en/she\", \"/c/en/her\", \"/c/en/hers\"]\n",
    "\n",
    "# --- Run calculations ---\n",
    "gender_dir = compute_gender_direction(gender_pairs, gender_pairs2, ppmi_df_var1)\n",
    "# SAME bias calculations\n",
    "bias_same_neutral = delta_same(neutral_words_target, attribute_set_a, attribute_set_b, ppmi_df_var1)\n",
    "bias_same_male = delta_same(male_words_target, attribute_set_a, attribute_set_b, ppmi_df_var1)\n",
    "bias_same_female = delta_same(female_words_target, attribute_set_a, attribute_set_b, ppmi_df_var1)\n",
    "# Direct bias calculations\n",
    "bias_direct = direct_bias(\"/c/en/doctor\", gender_dir, ppmi_df_var1)\n",
    "# Saving direct bias to csv \n",
    "output_dir = \"data/heuristic/directBias/variation1\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "female_biases = direct_bias_wordlist(female_words_target, gender_dir, ppmi_df_var1, \"female\", \"data/heuristic/directBias/variation1/female_bias.csv\")\n",
    "male_biases = direct_bias_wordlist(male_words_target, gender_dir, ppmi_df_var1, \"male\", \"data/heuristic/directBias/variation1/male_bias.csv\")\n",
    "neutral_biases = direct_bias_wordlist(neutral_words_target, gender_dir, ppmi_df_var1, \"neutral\", \"data/heuristic/directBias/variation1/neutral_bias.csv\")\n",
    "\n",
    "print(\"Gender direction (preview):\", gender_dir[:5])\n",
    "print(\"SAME bias score neutral:\", bias_same_neutral)\n",
    "print(\"SAME bias score male:\", bias_same_male)\n",
    "print(\"SAME bias score female:\", bias_same_female)\n",
    "print(\"Direct bias for '/c/en/doctor':\", bias_direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender direction (preview): [ 3.66054305e-15 -1.09158502e-15  6.77944930e-16 -1.81073787e-15\n",
      "  1.39121626e-16]\n",
      "SAME bias score neutral: 0.019407439451583946\n",
      "SAME bias score male: 0.2681759497124818\n",
      "SAME bias score female: -0.5816567944429101\n",
      "Direct bias for '/c/en/doctor': 0.6483519823562606\n"
     ]
    }
   ],
   "source": [
    "# Variation 2: Small dataset + Filter (\"/r/Antonym\", \"/r/NotDesires\", \"/r/Desires\", \"/r/ObstructedBy\", \"/r/MannerOf\")\n",
    "# First have to edit scraper for filtering.\n",
    "df = pd.read_csv(\"data/conceptnet_api/csv/edge_extractVar2.csv\")\n",
    "# print(df.shape)\n",
    "# print(df['weight'].describe())\n",
    "# df.head(3)\n",
    "ppmi_df_var2 = build_ppmi(conceptnet_filename=\"data/conceptnet_api/csv/edge_extractVar2.csv\", ndim=300)\n",
    "save_hdf(ppmi_df_var2, filename='data/conceptnet_api/hdf/testVar2.hdf')\n",
    "\n",
    "gender_pairs = [(\"/c/en/man\", \"/c/en/woman\")]\n",
    "gender_pairs2 = [(\"/c/en/men\", \"/c/en/women\")]\n",
    "attribute_set_a = [\"/c/en/he\", \"/c/en/him\", \"/c/en/his\"]\n",
    "attribute_set_b = [\"/c/en/she\", \"/c/en/her\", \"/c/en/hers\"]\n",
    "\n",
    "# --- Run calculations ---\n",
    "gender_dir = compute_gender_direction(gender_pairs, gender_pairs2, ppmi_df_var2)\n",
    "# SAME bias calculations\n",
    "bias_same_neutral = delta_same(neutral_words_target, attribute_set_a, attribute_set_b, ppmi_df_var2)\n",
    "bias_same_male = delta_same(male_words_target, attribute_set_a, attribute_set_b, ppmi_df_var2)\n",
    "bias_same_female = delta_same(female_words_target, attribute_set_a, attribute_set_b, ppmi_df_var2)\n",
    "# Direct bias calculations\n",
    "bias_direct = direct_bias(\"/c/en/doctor\", gender_dir, ppmi_df_var2)\n",
    "# Saving direct bias to csv \n",
    "output_dir = \"data/heuristic/directBias/variation2\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "female_biases = direct_bias_wordlist(female_words_target, gender_dir, ppmi_df_var2, \"female\", \"data/heuristic/directBias/variation2/female_bias.csv\")\n",
    "male_biases = direct_bias_wordlist(male_words_target, gender_dir, ppmi_df_var2, \"male\", \"data/heuristic/directBias/variation2/male_bias.csv\")\n",
    "neutral_biases = direct_bias_wordlist(neutral_words_target, gender_dir, ppmi_df_var2, \"neutral\", \"data/heuristic/directBias/variation2/neutral_bias.csv\")\n",
    "\n",
    "print(\"Gender direction (preview):\", gender_dir[:5])\n",
    "print(\"SAME bias score neutral:\", bias_same_neutral)\n",
    "print(\"SAME bias score male:\", bias_same_male)\n",
    "print(\"SAME bias score female:\", bias_same_female)\n",
    "print(\"Direct bias for '/c/en/doctor':\", bias_direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral coverage:\n",
      "✔ Found 115 words, ❌ Missing 5238 words\n",
      "Male coverage:\n",
      "✔ Found 29 words, ❌ Missing 494 words\n",
      "Female coverage:\n",
      "✔ Found 15 words, ❌ Missing 352 words\n",
      "Index(['/c/en/help_child', '/c/en/adult', '/c/en/man', '/c/en/sign_contract',\n",
      "       '/c/en/dress_herself', '/c/en/sheep', '/c/en/adult/n/wn/person',\n",
      "       '/c/en/fascist/n/wn/person', '/c/en/man/n/wn/person',\n",
      "       '/c/en/stay_at_home/n/wn/person',\n",
      "       ...\n",
      "       '/c/en/quarryman/n/wn/person', '/c/en/slave/n/wn/person',\n",
      "       '/c/en/tier/n/wn/person', '/c/en/political_officer/n',\n",
      "       '/c/en/employable/n/wn/person', '/c/en/throwster/n/wn/person',\n",
      "       '/c/en/freelance/n/wn/person', '/c/en/skidder/n/wn/person',\n",
      "       '/c/en/solderer/n/wn/person', '/c/en/bleacher/n/wn/person'],\n",
      "      dtype='object', length=3958)\n"
     ]
    }
   ],
   "source": [
    "def check_vocab_coverage(word_list, ppmi_df):\n",
    "    present = [w for w in word_list if w in ppmi_df.index]\n",
    "    missing = [w for w in word_list if w not in ppmi_df.index]\n",
    "    print(f\"✔ Found {len(present)} words, ❌ Missing {len(missing)} words\")\n",
    "    return present, missing\n",
    "\n",
    "print(\"Neutral coverage:\")\n",
    "_, _ = check_vocab_coverage(neutral_words_target, ppmi_df_var2)\n",
    "\n",
    "print(\"Male coverage:\")\n",
    "_, _ = check_vocab_coverage(male_words_target, ppmi_df_var2)\n",
    "\n",
    "print(\"Female coverage:\")\n",
    "_, _ = check_vocab_coverage(female_words_target, ppmi_df_var2)\n",
    "\n",
    "print(ppmi_df_var2.index)\n",
    "\n",
    "## From here, realised that we are not getting alot of coverage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender direction (preview): [-1.07127059e-17  1.20317390e-15 -7.71549783e-16 -3.44391595e-16\n",
      "  2.96811941e-05]\n",
      "SAME bias score neutral: 0.02209098032974399\n",
      "SAME bias score male: 0.22033426697084874\n",
      "SAME bias score female: -0.5469579272834754\n",
      "Direct bias for '/c/en/doctor': 0.6910107221797888\n"
     ]
    }
   ],
   "source": [
    "# Variation 3: Small dataset + Filter (Unidirectional edges)\n",
    "# First have to edit scraper for filtering.\n",
    "df = pd.read_csv(\"data/conceptnet_api/csv/edge_extractVar3.csv\")\n",
    "# print(df.shape)\n",
    "# print(df['weight'].describe())\n",
    "# df.head(3)\n",
    "# Edit the Var numbers below. E.g. edge_extractVar<NUMBER> and testVar<NUMBER>\n",
    "ppmi_df_var3 = build_ppmi(conceptnet_filename=\"data/conceptnet_api/csv/edge_extractVar3.csv\", ndim=300)\n",
    "save_hdf(ppmi_df_var3, filename='data/conceptnet_api/hdf/testVar3.hdf')\n",
    "\n",
    "gender_pairs = [(\"/c/en/man\", \"/c/en/woman\")]\n",
    "gender_pairs2 = [(\"/c/en/men\", \"/c/en/women\")]\n",
    "attribute_set_a = [\"/c/en/he\", \"/c/en/him\", \"/c/en/his\"]\n",
    "attribute_set_b = [\"/c/en/she\", \"/c/en/her\", \"/c/en/hers\"]\n",
    "\n",
    "# --- Run calculations ---\n",
    "gender_dir = compute_gender_direction(gender_pairs, gender_pairs2, ppmi_df_var3)\n",
    "# SAME bias calculations\n",
    "bias_same_neutral = delta_same(neutral_words_target, attribute_set_a, attribute_set_b, ppmi_df_var3)\n",
    "bias_same_male = delta_same(male_words_target, attribute_set_a, attribute_set_b, ppmi_df_var3)\n",
    "bias_same_female = delta_same(female_words_target, attribute_set_a, attribute_set_b, ppmi_df_var3)\n",
    "# Direct bias calculations\n",
    "bias_direct = direct_bias(\"/c/en/doctor\", gender_dir, ppmi_df_var3)\n",
    "# Saving direct bias to csv \n",
    "output_dir = \"data/heuristic/directBias/variation3\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "female_biases = direct_bias_wordlist(female_words_target, gender_dir, ppmi_df_var3, \"female\", \"data/heuristic/directBias/variation3/female_bias.csv\")\n",
    "male_biases = direct_bias_wordlist(male_words_target, gender_dir, ppmi_df_var3, \"male\", \"data/heuristic/directBias/variation3/male_bias.csv\")\n",
    "neutral_biases = direct_bias_wordlist(neutral_words_target, gender_dir, ppmi_df_var3, \"neutral\", \"data/heuristic/directBias/variation3/neutral_bias.csv\")\n",
    "\n",
    "print(\"Gender direction (preview):\", gender_dir[:5])\n",
    "print(\"SAME bias score neutral:\", bias_same_neutral)\n",
    "print(\"SAME bias score male:\", bias_same_male)\n",
    "print(\"SAME bias score female:\", bias_same_female)\n",
    "print(\"Direct bias for '/c/en/doctor':\", bias_direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:00<00:00, 945.98it/s]\n",
      "100%|██████████| 67/67 [00:00<00:00, 893.61it/s]\n",
      "100%|██████████| 67/67 [00:00<00:00, 1013.00it/s]\n",
      "100%|██████████| 67/67 [00:00<00:00, 973.38it/s]\n",
      "100%|██████████| 67/67 [00:00<00:00, 955.85it/s]\n",
      "100%|██████████| 67/67 [00:00<00:00, 944.36it/s]\n",
      "100%|██████████| 67/67 [00:00<00:00, 905.39it/s]\n",
      "100%|██████████| 67/67 [00:00<00:00, 958.68it/s]\n",
      "100%|██████████| 67/67 [00:00<00:00, 1029.19it/s]\n",
      "100%|██████████| 67/67 [00:00<00:00, 1042.43it/s]\n",
      "100%|██████████| 67/67 [00:00<00:00, 1036.17it/s]\n",
      "100%|██████████| 67/67 [00:00<00:00, 1040.70it/s]\n",
      "100%|██████████| 67/67 [00:00<00:00, 958.45it/s]\n",
      "100%|██████████| 67/67 [00:00<00:00, 900.66it/s]\n",
      "100%|██████████| 67/67 [00:00<00:00, 923.82it/s]\n",
      "100%|██████████| 67/67 [00:00<00:00, 932.86it/s]\n",
      "100%|██████████| 67/67 [00:00<00:00, 491.19it/s]\n",
      "100%|██████████| 67/67 [00:00<00:00, 947.51it/s]\n",
      "100%|██████████| 67/67 [00:00<00:00, 982.72it/s]\n",
      "100%|██████████| 67/67 [00:00<00:00, 1056.85it/s]\n",
      "100%|██████████| 67/67 [00:00<00:00, 1072.10it/s]\n",
      "100%|██████████| 67/67 [00:00<00:00, 1031.74it/s]\n",
      "100%|██████████| 67/67 [00:00<00:00, 900.75it/s]\n",
      "100%|██████████| 67/67 [00:00<00:00, 876.22it/s]\n",
      "100%|██████████| 67/67 [00:00<00:00, 853.46it/s]\n",
      "100%|██████████| 67/67 [00:00<00:00, 827.54it/s]\n"
     ]
    }
   ],
   "source": [
    "### Hypothesis 2:\n",
    "## Scraping from ConceptNet\n",
    "import filter_ablation\n",
    "import importlib\n",
    "import conceptnet_api_scraper\n",
    "importlib.reload(conceptnet_api_scraper)\n",
    "importlib.reload(filter_ablation)\n",
    "from conceptnet_api_scraper import parse_response\n",
    "\n",
    "JSON_PATH = os.path.join(os.getcwd(), \"data\", \"conceptnet_api\", \"json\")\n",
    "CSV_PATH = os.path.join(os.getcwd(), \"data\", \"conceptnet_api\", \"csv\")\n",
    "\n",
    "for filter_name, filter in filter_ablation.get_all_filter_chains().items(): \n",
    "  keywords_df = parse_response(input_folder=JSON_PATH, output_folder=CSV_PATH, edge_filter=filter)\n",
    "  keywords_df.to_csv(f'{CSV_PATH}/edge_extract_{filter_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(glove_path):\n",
    "    glove_dict = {}\n",
    "    with open(glove_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            word = parts[0]\n",
    "            vec = np.array(parts[1:], dtype=np.float32)\n",
    "            glove_dict[word] = vec\n",
    "    return glove_dict\n",
    "\n",
    "glove_dict = load_glove_embeddings(\"data/conceptnet_api/glove.6B/glove.6B.300d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Util functions\n",
    "def from_conceptnet_uri(uri):\n",
    "    return uri.replace(\"/c/en/\", \"\").replace(\"_\", \" \")\n",
    "\n",
    "# Function to get cosine similarity between GloVe and ConceptNet embeddings\n",
    "def compare_glove_conceptnet(uri_list, group_name, glove_dict, conceptnet_dict):\n",
    "    similarities = []\n",
    "    for uri in uri_list:\n",
    "        word = from_conceptnet_uri(uri)\n",
    "        if word in glove_dict and uri in conceptnet_dict:\n",
    "            sim = cosine_similarity(glove_dict[word], conceptnet_dict[uri])\n",
    "            similarities.append((word, sim))\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Processing filter variation: baseline\n",
      "📊 SAME Bias (Neutral): 0.033242006\n",
      "📊 SAME Bias (Male): 0.25216886\n",
      "📊 SAME Bias (Female): -0.5132581\n",
      "📊 Direct Bias ('/c/en/doctor'): 0.452215\n",
      "✅ Completed variation: baseline\n",
      "\n",
      "🚀 Processing filter variation: baseline_lenient\n",
      "📊 SAME Bias (Neutral): 0.026784547\n",
      "📊 SAME Bias (Male): 0.22245887\n",
      "📊 SAME Bias (Female): -0.35154822\n",
      "📊 Direct Bias ('/c/en/doctor'): 0.47130355\n",
      "✅ Completed variation: baseline_lenient\n",
      "\n",
      "🚀 Processing filter variation: baseline_strict\n",
      "📊 SAME Bias (Neutral): 0.027497778\n",
      "📊 SAME Bias (Male): 0.36770976\n",
      "📊 SAME Bias (Female): -0.41915584\n",
      "📊 Direct Bias ('/c/en/doctor'): 0.48330107\n",
      "✅ Completed variation: baseline_strict\n",
      "\n",
      "🚀 Processing filter variation: comprehensive\n",
      "📊 SAME Bias (Neutral): 0.047786843\n",
      "📊 SAME Bias (Male): 0.19768564\n",
      "📊 SAME Bias (Female): -0.42035985\n",
      "📊 Direct Bias ('/c/en/doctor'): 0.5072794\n",
      "✅ Completed variation: comprehensive\n",
      "\n",
      "🚀 Processing filter variation: comprehensive_high_quality\n",
      "📊 SAME Bias (Neutral): 0.048887245\n",
      "📊 SAME Bias (Male): 0.20690332\n",
      "📊 SAME Bias (Female): -0.41433895\n",
      "📊 Direct Bias ('/c/en/doctor'): 0.51384854\n",
      "✅ Completed variation: comprehensive_high_quality\n",
      "\n",
      "🚀 Processing filter variation: comprehensive_lenient\n",
      "📊 SAME Bias (Neutral): 0.031263314\n",
      "📊 SAME Bias (Male): 0.3622681\n",
      "📊 SAME Bias (Female): -0.46502426\n",
      "📊 Direct Bias ('/c/en/doctor'): 0.5103363\n",
      "✅ Completed variation: comprehensive_lenient\n",
      "\n",
      "🚀 Processing filter variation: comprehensive_strict\n",
      "📊 SAME Bias (Neutral): 0.048887245\n",
      "📊 SAME Bias (Male): 0.20690332\n",
      "📊 SAME Bias (Female): -0.41433895\n",
      "📊 Direct Bias ('/c/en/doctor'): 0.5138485\n",
      "✅ Completed variation: comprehensive_strict\n",
      "\n",
      "🚀 Processing filter variation: high_quality\n",
      "📊 SAME Bias (Neutral): 0.0\n",
      "📊 SAME Bias (Male): 0.0\n",
      "📊 SAME Bias (Female): 0.0\n",
      "📊 Direct Bias ('/c/en/doctor'): 0\n",
      "✅ Completed variation: high_quality\n",
      "\n",
      "🚀 Processing filter variation: relation_minimal\n",
      "📊 SAME Bias (Neutral): 0.0\n",
      "📊 SAME Bias (Male): 0.0\n",
      "📊 SAME Bias (Female): 0.0\n",
      "📊 Direct Bias ('/c/en/doctor'): 0\n",
      "✅ Completed variation: relation_minimal\n",
      "\n",
      "🚀 Processing filter variation: relation_minimal_properties_synonyms_capabilities\n",
      "📊 SAME Bias (Neutral): 0.0\n",
      "📊 SAME Bias (Male): 0.0\n",
      "📊 SAME Bias (Female): 0.0\n",
      "📊 Direct Bias ('/c/en/doctor'): 0\n",
      "✅ Completed variation: relation_minimal_properties_synonyms_capabilities\n",
      "\n",
      "🚀 Processing filter variation: relation_minimal_synonyms\n",
      "📊 SAME Bias (Neutral): 0.0\n",
      "📊 SAME Bias (Male): 0.0\n",
      "📊 SAME Bias (Female): 0.0\n",
      "📊 Direct Bias ('/c/en/doctor'): 0\n",
      "✅ Completed variation: relation_minimal_synonyms\n",
      "\n",
      "🚀 Processing filter variation: relation_minimal_synonyms_capabilities\n",
      "📊 SAME Bias (Neutral): 0.0\n",
      "📊 SAME Bias (Male): 0.0\n",
      "📊 SAME Bias (Female): 0.0\n",
      "📊 Direct Bias ('/c/en/doctor'): 0\n",
      "✅ Completed variation: relation_minimal_synonyms_capabilities\n",
      "\n",
      "🚀 Processing filter variation: relation_specific\n",
      "📊 SAME Bias (Neutral): 0.036618486\n",
      "📊 SAME Bias (Male): 0.16052204\n",
      "📊 SAME Bias (Female): -0.36008668\n",
      "📊 Direct Bias ('/c/en/doctor'): 0.49859512\n",
      "✅ Completed variation: relation_specific\n",
      "\n",
      "🚀 Processing filter variation: remove_relation_type_antonym\n",
      "📊 SAME Bias (Neutral): 0.027653804\n",
      "📊 SAME Bias (Male): 0.22699587\n",
      "📊 SAME Bias (Female): -0.36863095\n",
      "📊 Direct Bias ('/c/en/doctor'): 0.47329438\n",
      "✅ Completed variation: remove_relation_type_antonym\n",
      "\n",
      "🚀 Processing filter variation: remove_relation_type_antonym_notdesires\n",
      "📊 SAME Bias (Neutral): 0.028463801\n",
      "📊 SAME Bias (Male): 0.22778596\n",
      "📊 SAME Bias (Female): -0.3688392\n",
      "📊 Direct Bias ('/c/en/doctor'): 0.47962666\n",
      "✅ Completed variation: remove_relation_type_antonym_notdesires\n",
      "\n",
      "🚀 Processing filter variation: remove_relation_type_antonym_notdesires_desires\n",
      "📊 SAME Bias (Neutral): 0.029746503\n",
      "📊 SAME Bias (Male): 0.22886485\n",
      "📊 SAME Bias (Female): -0.36887103\n",
      "📊 Direct Bias ('/c/en/doctor'): 0.49751595\n",
      "✅ Completed variation: remove_relation_type_antonym_notdesires_desires\n",
      "\n",
      "🚀 Processing filter variation: remove_relation_type_antonym_notdesires_desires_obstructedby\n",
      "📊 SAME Bias (Neutral): 0.029746503\n",
      "📊 SAME Bias (Male): 0.22886485\n",
      "📊 SAME Bias (Female): -0.36887106\n",
      "📊 Direct Bias ('/c/en/doctor'): 0.497516\n",
      "✅ Completed variation: remove_relation_type_antonym_notdesires_desires_obstructedby\n",
      "\n",
      "🚀 Processing filter variation: remove_relation_type_antonym_notdesires_desires_obstructedby_mannerof\n",
      "📊 SAME Bias (Neutral): 0.029781956\n",
      "📊 SAME Bias (Male): 0.22888593\n",
      "📊 SAME Bias (Female): -0.3688953\n",
      "📊 Direct Bias ('/c/en/doctor'): 0.49754\n",
      "✅ Completed variation: remove_relation_type_antonym_notdesires_desires_obstructedby_mannerof\n",
      "\n",
      "🚀 Processing filter variation: remove_relation_type_antonym_notdesires_desires_obstructedby_mannerof_causesdesire\n",
      "📊 SAME Bias (Neutral): 0.02978429\n",
      "📊 SAME Bias (Male): 0.22888924\n",
      "📊 SAME Bias (Female): -0.36889786\n",
      "📊 Direct Bias ('/c/en/doctor'): 0.49754363\n",
      "✅ Completed variation: remove_relation_type_antonym_notdesires_desires_obstructedby_mannerof_causesdesire\n",
      "\n",
      "🚀 Processing filter variation: semantic_similarity\n",
      "Skipping pair (/c/en/man, /c/en/woman) — one or both not in PPMI (primary).\n",
      "📊 SAME Bias (Neutral): 0.0\n",
      "📊 SAME Bias (Male): 0.0\n",
      "📊 SAME Bias (Female): 0.0\n",
      "📊 Direct Bias ('/c/en/doctor'): 0.027852822\n",
      "✅ Completed variation: semantic_similarity\n",
      "\n",
      "🚀 Processing filter variation: semantic_similarity_lenient\n",
      "📊 SAME Bias (Neutral): 0.0\n",
      "📊 SAME Bias (Male): 0.0\n",
      "📊 SAME Bias (Female): 0.0\n",
      "📊 Direct Bias ('/c/en/doctor'): 0.035996597\n",
      "✅ Completed variation: semantic_similarity_lenient\n",
      "\n",
      "🚀 Processing filter variation: semantic_similarity_low_weight\n",
      "📊 SAME Bias (Neutral): -0.07305399\n",
      "📊 SAME Bias (Male): 0.20795643\n",
      "📊 SAME Bias (Female): -0.18979275\n",
      "📊 Direct Bias ('/c/en/doctor'): 0.035014097\n",
      "✅ Completed variation: semantic_similarity_low_weight\n",
      "\n",
      "🚀 Processing filter variation: statistical_outliers\n",
      "📊 SAME Bias (Neutral): 0.11046432703733444\n",
      "📊 SAME Bias (Male): 0.46464017033576965\n",
      "📊 SAME Bias (Female): -0.015264100395143032\n",
      "📊 Direct Bias ('/c/en/doctor'): 0.6528007\n",
      "✅ Completed variation: statistical_outliers\n",
      "\n",
      "🚀 Processing filter variation: statistical_outliers_conservative\n",
      "📊 SAME Bias (Neutral): 0.0929485559463501\n",
      "📊 SAME Bias (Male): 0.48961564898490906\n",
      "📊 SAME Bias (Female): 0.10424938052892685\n",
      "📊 Direct Bias ('/c/en/doctor'): 0.665626\n",
      "✅ Completed variation: statistical_outliers_conservative\n",
      "\n",
      "🚀 Processing filter variation: statistical_outliers_top10\n",
      "📊 SAME Bias (Neutral): 0.11046432703733444\n",
      "📊 SAME Bias (Male): 0.46464017033576965\n",
      "📊 SAME Bias (Female): -0.01526410412043333\n",
      "📊 Direct Bias ('/c/en/doctor'): 0.6528006\n",
      "✅ Completed variation: statistical_outliers_top10\n",
      "\n",
      "🚀 Processing filter variation: statistical_outliers_top100\n",
      "📊 SAME Bias (Neutral): 0.11046432703733444\n",
      "📊 SAME Bias (Male): 0.46464017033576965\n",
      "📊 SAME Bias (Female): -0.015264102257788181\n",
      "📊 Direct Bias ('/c/en/doctor'): 0.6528006\n",
      "✅ Completed variation: statistical_outliers_top100\n"
     ]
    }
   ],
   "source": [
    "### Hypothesis 2: \n",
    "## Generating the heuristic scores\n",
    "import os\n",
    "import pandas as pd\n",
    "from utils.retrofit import sharded_retrofit, join_shards\n",
    "\n",
    "# === Paths ===\n",
    "CSV_PATH = \"data/conceptnet_api/csv\"\n",
    "HDF_PATH = \"data/conceptnet_api/hdf\"\n",
    "RETROFIT_PATH = \"data/conceptnet_api/retrofit\"\n",
    "BIAS_OUTPUT_ROOT = \"data/heuristic/directBias\"\n",
    "EVAL_OUTPUT = \"data/conceptnet_api/eval\"\n",
    "os.makedirs(HDF_PATH, exist_ok=True)\n",
    "os.makedirs(RETROFIT_PATH, exist_ok=True)\n",
    "os.makedirs(BIAS_OUTPUT_ROOT, exist_ok=True)\n",
    "os.makedirs(EVAL_OUTPUT, exist_ok=True)\n",
    "\n",
    "# === Bias Config ===\n",
    "gender_pairs = [(\"/c/en/man\", \"/c/en/woman\")]\n",
    "gender_pairs2 = [(\"/c/en/men\", \"/c/en/women\")]\n",
    "attribute_set_a = [\"/c/en/he\", \"/c/en/him\", \"/c/en/his\"]\n",
    "attribute_set_b = [\"/c/en/she\", \"/c/en/her\", \"/c/en/hers\"]\n",
    "\n",
    "# === Target Word Lists ===\n",
    "\n",
    "csv_files = [f for f in os.listdir(CSV_PATH) if f.startswith(\"edge_extract_\") and f.endswith(\".csv\")]\n",
    "\n",
    "for file in csv_files:\n",
    "    filter_name = file.replace(\"edge_extract_\", \"\").replace(\".csv\", \"\")\n",
    "    print(f\"\\n🚀 Processing filter variation: {filter_name}\")\n",
    "\n",
    "    # Step 1: Build PPMI\n",
    "    input_csv = os.path.join(CSV_PATH, file)\n",
    "    dense_hdf_path = os.path.join(HDF_PATH, f\"test_{filter_name}.hdf\")\n",
    "    ppmi_df = build_ppmi(conceptnet_filename=input_csv, ndim=300)\n",
    "    save_hdf(ppmi_df, filename=dense_hdf_path)\n",
    "\n",
    "    # Step 2: Retrofitting\n",
    "    retrofit_prefix = os.path.join(RETROFIT_PATH, f\"test_retrofitted_{filter_name}\")\n",
    "    sharded_retrofit(\n",
    "        dense_hdf_filename=dense_hdf_path,\n",
    "        conceptnet_filename=input_csv,\n",
    "        output_filename=retrofit_prefix\n",
    "    )\n",
    "\n",
    "    # Step 3: Join shards\n",
    "    join_shards(output_filename=retrofit_prefix, nshards=10, sort=False)\n",
    "\n",
    "    # Step 4: Load retrofitted PPMI\n",
    "    retrofitted_hdf = retrofit_prefix  # joined result has no extension\n",
    "    if not os.path.exists(retrofitted_hdf):\n",
    "        print(f\"⚠️ Skipping {filter_name}, retrofitted file not found\")\n",
    "        continue\n",
    "\n",
    "    ppmi_df = pd.read_hdf(retrofitted_hdf)\n",
    "\n",
    "    conceptnet_dict = {k: v.values for k, v in ppmi_df.iterrows()}\n",
    "\n",
    "    female_similarities = compare_glove_conceptnet(female_words_target, \"female\", glove_dict, conceptnet_dict)\n",
    "    male_similarities = compare_glove_conceptnet(male_words_target, \"male\", glove_dict, conceptnet_dict)\n",
    "    neutral_similarities = compare_glove_conceptnet(neutral_words_target, \"neutral\", glove_dict, conceptnet_dict)\n",
    "\n",
    "    # Create a DataFrame from each similarity list\n",
    "    female_df_out = pd.DataFrame(female_similarities, columns=[\"word\", \"cosine_similarity\"])\n",
    "    male_df_out = pd.DataFrame(male_similarities, columns=[\"word\", \"cosine_similarity\"])\n",
    "    neutral_df_out = pd.DataFrame(neutral_similarities, columns=[\"word\", \"cosine_similarity\"])\n",
    "\n",
    "    # Define output filenames\n",
    "    similarity_dir = os.path.join(EVAL_OUTPUT, \"cosine_similarity\", filter_name)\n",
    "    os.makedirs(similarity_dir, exist_ok=True)\n",
    "\n",
    "    female_df_out.to_csv(os.path.join(similarity_dir, \"female_glove_vs_conceptnet.csv\"), index=False)\n",
    "    male_df_out.to_csv(os.path.join(similarity_dir, \"male_glove_vs_conceptnet.csv\"), index=False)\n",
    "    neutral_df_out.to_csv(os.path.join(similarity_dir, \"neutral_glove_vs_conceptnet.csv\"), index=False)\n",
    "\n",
    "    # Step 5: Compute bias heuristics\n",
    "    gender_dir = compute_gender_direction(gender_pairs, gender_pairs2, ppmi_df)\n",
    "\n",
    "    bias_same_neutral = delta_same(neutral_words_target, attribute_set_a, attribute_set_b, ppmi_df)\n",
    "    bias_same_male = delta_same(male_words_target, attribute_set_a, attribute_set_b, ppmi_df)\n",
    "    bias_same_female = delta_same(female_words_target, attribute_set_a, attribute_set_b, ppmi_df)\n",
    "    bias_direct_doctor = direct_bias(\"/c/en/doctor\", gender_dir, ppmi_df)\n",
    "\n",
    "    # Step 6: Save direct bias scores\n",
    "    output_dir = os.path.join(BIAS_OUTPUT_ROOT, f\"variation_{filter_name}\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    direct_bias_wordlist(female_words_target, gender_dir, ppmi_df, \"female\", os.path.join(output_dir, \"female_bias.csv\"))\n",
    "    direct_bias_wordlist(male_words_target, gender_dir, ppmi_df, \"male\", os.path.join(output_dir, \"male_bias.csv\"))\n",
    "    direct_bias_wordlist(neutral_words_target, gender_dir, ppmi_df, \"neutral\", os.path.join(output_dir, \"neutral_bias.csv\"))\n",
    "\n",
    "    # Step 7: Summary print\n",
    "    print(\"📊 SAME Bias (Neutral):\", bias_same_neutral)\n",
    "    print(\"📊 SAME Bias (Male):\", bias_same_male)\n",
    "    print(\"📊 SAME Bias (Female):\", bias_same_female)\n",
    "    print(\"📊 Direct Bias ('/c/en/doctor'):\", bias_direct_doctor)\n",
    "    print(f\"✅ Completed variation: {filter_name}\")\n",
    "\n",
    "    # Only overwrite the file the first time\n",
    "    if 'first_write' not in globals():\n",
    "        first_write = True\n",
    "\n",
    "    summary_path = os.path.join(EVAL_OUTPUT, \"eval_summary.txt\")\n",
    "    mode = \"w\" if first_write else \"a\"\n",
    "\n",
    "    # Step 8: Save results summary to a .txt file\n",
    "    with open(summary_path, mode) as f:\n",
    "        f.write(f\"===== Bias Results for Filter: {filter_name} =====\\n\")\n",
    "        f.write(f\"SAME Bias (Neutral): {bias_same_neutral:.4f}\\n\")\n",
    "        f.write(f\"SAME Bias (Male):    {bias_same_male:.4f}\\n\")\n",
    "        f.write(f\"SAME Bias (Female):  {bias_same_female:.4f}\\n\")\n",
    "        f.write(f\"Direct Bias ('/c/en/doctor'): {bias_direct_doctor:.4f}\\n\")\n",
    "        f.write(\"--------------------------------------------------\\n\\n\")\n",
    "\n",
    "    first_write = False  # Switch to append mode after first time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some plots to visualise \n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Settings ---\n",
    "BASE_DIR = \"data/conceptnet_api/eval/cosine_similarity\"\n",
    "groups = [\"female\", \"male\", \"neutral\"]  # word group\n",
    "filters = os.listdir(BASE_DIR)          # auto-detect all filter folders\n",
    "\n",
    "# --- Collect Data ---\n",
    "data = []\n",
    "\n",
    "for filter_name in filters:\n",
    "    for group in groups:\n",
    "        file_path = os.path.join(BASE_DIR, filter_name, f\"{group}_glove_vs_conceptnet.csv\")\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path)\n",
    "            for _, row in df.iterrows():\n",
    "                data.append({\n",
    "                    \"word\": row[\"word\"],\n",
    "                    \"similarity\": row[\"cosine_similarity\"],\n",
    "                    \"group\": group,\n",
    "                    \"filter\": filter_name\n",
    "                })\n",
    "\n",
    "# --- Convert to DataFrame ---\n",
    "all_sim_df = pd.DataFrame(data)\n",
    "\n",
    "# --- Plot (One Plot Per Filter) ---\n",
    "for filter_name in all_sim_df[\"filter\"].unique():\n",
    "    subset = all_sim_df[all_sim_df[\"filter\"] == filter_name]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(data=subset, x=\"word\", y=\"similarity\", hue=\"group\", style=\"group\", s=80)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(f\"Cosine Similarity: GloVe vs ConceptNet — {filter_name}\")\n",
    "    plt.xlabel(\"Word\")\n",
    "    plt.ylabel(\"Cosine Similarity\")\n",
    "    plt.ylim(-1, 1)\n",
    "    plt.legend(title=\"Group\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"data/conceptnet_api/eval/cosine_similarity_plot_{filter_name}.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: baseline_albert\n",
      "Evaluating: custom_albert\n",
      "Evaluating: baseline_mobilebert\n",
      "Evaluating: custom_mobilebert\n"
     ]
    }
   ],
   "source": [
    "### Bernard's hdf files for evaluation \n",
    "retrofitted_baseline_albert = \"data/conceptnet_api/hdf/retrofitted-baseline-albert-128.hdf\"\n",
    "retrofitted_custom_albert = \"data/conceptnet_api/hdf/retrofitted-custom-albert-128.hdf\"\n",
    "retrofitted_baseline_mobilebert = \"data/conceptnet_api/hdf/retrofitted-baseline-mobilebert-128.hdf\"\n",
    "retrofitted_custom_mobilebert =  \"data/conceptnet_api/hdf/retrofitted-custom-mobilebert-128.hdf\"\n",
    "\n",
    "retrofitted_baseline_albert_df = pd.read_hdf(retrofitted_baseline_albert)\n",
    "retrofitted_custom_albert_df = pd.read_hdf(retrofitted_custom_albert)\n",
    "retrofitted_baseline_mobilebert_df = pd.read_hdf(retrofitted_baseline_mobilebert)\n",
    "retrofitted_custom_mobilebert_df = pd.read_hdf(retrofitted_custom_mobilebert)\n",
    "\n",
    "EVAL_OUTPUT = \"data/conceptnet_api/eval\"\n",
    "os.makedirs(EVAL_OUTPUT, exist_ok=True)\n",
    "summary_path = os.path.join(EVAL_OUTPUT, \"bert_eval_summary.txt\")\n",
    "\n",
    "embedding_variants = {\n",
    "    \"baseline_albert\": retrofitted_baseline_albert_df,\n",
    "    \"custom_albert\": retrofitted_custom_albert_df,\n",
    "    \"baseline_mobilebert\": retrofitted_baseline_mobilebert_df,\n",
    "    \"custom_mobilebert\": retrofitted_custom_mobilebert_df\n",
    "}\n",
    "\n",
    "with open(summary_path, \"w\") as f:\n",
    "    for name, ppmi_df in embedding_variants.items():\n",
    "        print(f\"Evaluating: {name}\")\n",
    "        f.write(f\"===== Evaluation for: {name} =====\\n\")\n",
    "\n",
    "        # Compute gender direction\n",
    "        try:\n",
    "            gender_dir = compute_gender_direction(gender_pairs, gender_pairs2, ppmi_df)\n",
    "        except ValueError as e:\n",
    "            f.write(f\"⚠️ Skipping {name}: {str(e)}\\n\\n\")\n",
    "            continue\n",
    "\n",
    "        # Compute SAME biases\n",
    "        bias_same_neutral = delta_same(neutral_words_target, attribute_set_a, attribute_set_b, ppmi_df)\n",
    "        bias_same_male = delta_same(male_words_target, attribute_set_a, attribute_set_b, ppmi_df)\n",
    "        bias_same_female = delta_same(female_words_target, attribute_set_a, attribute_set_b, ppmi_df)\n",
    "\n",
    "        # Compute direct bias for \"human\"\n",
    "        bias_direct_computer = direct_bias(\"/c/en/computer\", gender_dir, ppmi_df)\n",
    "\n",
    "        # Log to file\n",
    "        f.write(f\"SAME Bias (Neutral): {bias_same_neutral:.4f}\\n\")\n",
    "        f.write(f\"SAME Bias (Male):    {bias_same_male:.4f}\\n\")\n",
    "        f.write(f\"SAME Bias (Female):  {bias_same_female:.4f}\\n\")\n",
    "        f.write(f\"Direct Bias ('/c/en/computer'): {bias_direct_computer:.4f}\\n\")\n",
    "        f.write(\"--------------------------------------------------\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS4248",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
