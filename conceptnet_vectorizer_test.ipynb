{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from scipy.sparse import linalg\n",
    "\n",
    "from utils.sparse_matrix_builder import build_from_conceptnet_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ppmi(conceptnet_filename, ndim=300):\n",
    "    sparse_csr, index = build_from_conceptnet_table(conceptnet_filename)\n",
    "    ppmi = counts_to_ppmi(sparse_csr)\n",
    "    u, s, vT = linalg.svds(ppmi, ndim)\n",
    "    v = vT.T\n",
    "    values = (u + v) * (s ** 0.5)\n",
    "\n",
    "    return pd.DataFrame(values, index=index)\n",
    "\n",
    "\n",
    "def counts_to_ppmi(counts_csr, smoothing=0.75):\n",
    "    \"\"\"\n",
    "    Converts a sparse matrix of co-occurrences into a sparse matrix of positive\n",
    "    pointwise mutual information. Context distributional smoothing is applied\n",
    "    to the resulting matrix.\n",
    "    \"\"\"\n",
    "    # word_counts adds up the total amount of association for each term.\n",
    "    word_counts = np.asarray(counts_csr.sum(axis=1)).flatten()\n",
    "\n",
    "    # smooth_context_freqs represents the relative frequency of occurrence\n",
    "    # of each term as a context (a column of the table).\n",
    "    smooth_context_freqs = np.asarray(counts_csr.sum(axis=0)).flatten() ** smoothing\n",
    "    smooth_context_freqs /= smooth_context_freqs.sum()\n",
    "\n",
    "    # Divide each row of counts_csr by the word counts. We accomplish this by\n",
    "    # multiplying on the left by the sparse diagonal matrix of 1 / word_counts.\n",
    "    ppmi = sparse.diags(1 / word_counts).dot(counts_csr)\n",
    "\n",
    "    # Then, similarly divide the columns by smooth_context_freqs, by the same\n",
    "    # method except that we multiply on the right.\n",
    "    ppmi = ppmi.dot(sparse.diags(1 / smooth_context_freqs))\n",
    "\n",
    "    # Take the log of the resulting entries to give pointwise mutual\n",
    "    # information. Discard those whose PMI is less than 0, to give positive\n",
    "    # pointwise mutual information (PPMI).\n",
    "    ppmi.data = np.maximum(np.log(ppmi.data), 0)\n",
    "    ppmi.eliminate_zeros()\n",
    "    return ppmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4282, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end_id</th>\n",
       "      <th>end_label</th>\n",
       "      <th>start_id</th>\n",
       "      <th>start_label</th>\n",
       "      <th>rel_id</th>\n",
       "      <th>surface_text</th>\n",
       "      <th>weight</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/c/en/chair_meeting</td>\n",
       "      <td>chair a meeting</td>\n",
       "      <td>/c/en/chairperson</td>\n",
       "      <td>A chairperson</td>\n",
       "      <td>/r/CapableOf</td>\n",
       "      <td>[[A chairperson]] can [[chair a meeting]]</td>\n",
       "      <td>4.898979</td>\n",
       "      <td>/d/conceptnet/4/en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/c/en/chair</td>\n",
       "      <td>chair</td>\n",
       "      <td>/c/en/chairperson/n</td>\n",
       "      <td>chairperson</td>\n",
       "      <td>/r/Synonym</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>/d/wiktionary/en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/c/en/president/n/wn/person</td>\n",
       "      <td>president</td>\n",
       "      <td>/c/en/chairperson/n/wn/person</td>\n",
       "      <td>chairperson</td>\n",
       "      <td>/r/Synonym</td>\n",
       "      <td>[[chairperson]] is a synonym of [[president]]</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>/d/wordnet/3.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        end_id        end_label  \\\n",
       "0          /c/en/chair_meeting  chair a meeting   \n",
       "1                  /c/en/chair            chair   \n",
       "2  /c/en/president/n/wn/person        president   \n",
       "\n",
       "                        start_id    start_label        rel_id  \\\n",
       "0              /c/en/chairperson  A chairperson  /r/CapableOf   \n",
       "1            /c/en/chairperson/n    chairperson    /r/Synonym   \n",
       "2  /c/en/chairperson/n/wn/person    chairperson    /r/Synonym   \n",
       "\n",
       "                                    surface_text    weight             dataset  \n",
       "0      [[A chairperson]] can [[chair a meeting]]  4.898979  /d/conceptnet/4/en  \n",
       "1                                            NaN  2.000000    /d/wiktionary/en  \n",
       "2  [[chairperson]] is a synonym of [[president]]  2.000000      /d/wordnet/3.1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/conceptnet_api/csv/edge_extract.csv\")\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4282.000000\n",
       "mean        1.529992\n",
       "std         0.916131\n",
       "min         0.779000\n",
       "25%         1.000000\n",
       "50%         1.000000\n",
       "75%         2.000000\n",
       "max        13.576303\n",
       "Name: weight, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['weight'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_422768/192728236.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  ppmi = sparse.diags(1 / word_counts).dot(counts_csr)\n",
      "/tmp/ipykernel_422768/192728236.py:31: RuntimeWarning: divide by zero encountered in divide\n",
      "  ppmi = ppmi.dot(sparse.diags(1 / smooth_context_freqs))\n"
     ]
    }
   ],
   "source": [
    "sparse_csr, index = build_from_conceptnet_table(\"data/conceptnet_api/csv/edge_extract.csv\")\n",
    "ppmi = counts_to_ppmi(sparse_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ** On entry to DLASCL parameter number  4 had an illegal value\n",
      " ** On entry to DLASCL parameter number  4 had an illegal value\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_422768/192728236.py:27: RuntimeWarning: divide by zero encountered in divide\n",
      "  ppmi = sparse.diags(1 / word_counts).dot(counts_csr)\n",
      "/tmp/ipykernel_422768/192728236.py:31: RuntimeWarning: divide by zero encountered in divide\n",
      "  ppmi = ppmi.dot(sparse.diags(1 / smooth_context_freqs))\n"
     ]
    },
    {
     "ename": "ArpackError",
     "evalue": "ARPACK error -9999: Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mArpackError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# build_ppmi(conceptnet_filename=\"data/conceptnet_api/csv/test_reduced.csv\", ndim=20)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mbuild_ppmi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconceptnet_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/conceptnet_api/csv/edge_extract.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mbuild_ppmi\u001b[39m\u001b[34m(conceptnet_filename, ndim)\u001b[39m\n\u001b[32m      2\u001b[39m sparse_csr, index = build_from_conceptnet_table(conceptnet_filename)\n\u001b[32m      3\u001b[39m ppmi = counts_to_ppmi(sparse_csr)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m u, s, vT = \u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43msvds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mppmi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m v = vT.T\n\u001b[32m      6\u001b[39m values = (u + v) * (s ** \u001b[32m0.5\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cs4248_project/lib/python3.11/site-packages/scipy/_lib/_util.py:440\u001b[39m, in \u001b[36m_transition_to_rng.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    433\u001b[39m     message = (\n\u001b[32m    434\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe NumPy global RNG was seeded by calling \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    435\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`np.random.seed`. Beginning in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, this \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    436\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfunction will no longer use the global RNG.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    437\u001b[39m     ) + cmn_msg\n\u001b[32m    438\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cs4248_project/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:509\u001b[39m, in \u001b[36msvds\u001b[39m\u001b[34m(A, k, ncv, tol, which, v0, maxiter, return_singular_vectors, solver, rng, options)\u001b[39m\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m v0 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    508\u001b[39m     v0 = rng.standard_normal(size=(\u001b[38;5;28mmin\u001b[39m(A.shape),))\n\u001b[32m--> \u001b[39m\u001b[32m509\u001b[39m _, eigvec = \u001b[43meigsh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXH_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtol\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    510\u001b[39m \u001b[43m                  \u001b[49m\u001b[43mncv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mncv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhich\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhich\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv0\u001b[49m\u001b[43m=\u001b[49m\u001b[43mv0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    511\u001b[39m \u001b[38;5;66;03m# arpack do not guarantee exactly orthonormal eigenvectors\u001b[39;00m\n\u001b[32m    512\u001b[39m \u001b[38;5;66;03m# for clustered eigenvalues, especially in complex arithmetic\u001b[39;00m\n\u001b[32m    513\u001b[39m eigvec, _ = np.linalg.qr(eigvec)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cs4248_project/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py:1696\u001b[39m, in \u001b[36meigsh\u001b[39m\u001b[34m(A, k, M, sigma, which, v0, ncv, maxiter, tol, return_eigenvectors, Minv, OPinv, mode)\u001b[39m\n\u001b[32m   1694\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _ARPACK_LOCK:\n\u001b[32m   1695\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m params.converged:\n\u001b[32m-> \u001b[39m\u001b[32m1696\u001b[39m         \u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43miterate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1698\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m params.extract(return_eigenvectors)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cs4248_project/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py:578\u001b[39m, in \u001b[36m_SymmetricArpackParams.iterate\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    576\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_no_convergence()\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m578\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ArpackError(\u001b[38;5;28mself\u001b[39m.info, infodict=\u001b[38;5;28mself\u001b[39m.iterate_infodict)\n",
      "\u001b[31mArpackError\u001b[39m: ARPACK error -9999: Could not build an Arnoldi factorization. IPARAM(5) returns the size of the current Arnoldi factorization. The user is advised to check that enough workspace and array storage has been allocated."
     ]
    }
   ],
   "source": [
    "# build_ppmi(conceptnet_filename=\"data/conceptnet_api/csv/test_reduced.csv\", ndim=20)\n",
    "build_ppmi(conceptnet_filename=\"data/conceptnet_api/csv/edge_extract.csv\", ndim=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs4248_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
