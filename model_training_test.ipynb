{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AdamW' from 'transformers' (/home/bernard/miniconda3/envs/cs4248_project/lib/python3.11/site-packages/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel, AutoModel, AutoConfig, AutoModelForSequenceClassification \u001b[38;5;66;03m# Or your task-specific model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AdamW\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfiguration_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'AdamW' from 'transformers' (/home/bernard/miniconda3/envs/cs4248_project/lib/python3.11/site-packages/transformers/__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils.formats import load_hdf, save_hdf\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import PreTrainedModel, AutoModel, AutoConfig, AutoModelForSequenceClassification # Or your task-specific model\n",
    "from transformers import AdamW\n",
    "from transformers.configuration_utils import PretrainedConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Dataset with Pre-Computed Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embeddings: Pre-computed embeddings (numpy array or torch tensor)\n",
    "                       Shape: (num_samples, seq_length, embedding_dim)\n",
    "            labels: Corresponding labels\n",
    "        \"\"\"\n",
    "        self.embeddings = torch.tensor(embeddings, dtype=torch.float)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_embeddings': self.embeddings[idx],\n",
    "            'labels': self.labels[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/c/en/chair_meeting</th>\n",
       "      <td>-4.221157e-17</td>\n",
       "      <td>6.753685e-16</td>\n",
       "      <td>1.230684e-17</td>\n",
       "      <td>2.004569e-07</td>\n",
       "      <td>-3.139845e-07</td>\n",
       "      <td>6.492718e-08</td>\n",
       "      <td>-5.941687e-16</td>\n",
       "      <td>-7.451524e-16</td>\n",
       "      <td>-3.245492e-16</td>\n",
       "      <td>1.050718e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029592</td>\n",
       "      <td>0.028524</td>\n",
       "      <td>-0.038507</td>\n",
       "      <td>-0.051363</td>\n",
       "      <td>-0.052692</td>\n",
       "      <td>-0.054144</td>\n",
       "      <td>-0.052064</td>\n",
       "      <td>-0.045782</td>\n",
       "      <td>-0.061692</td>\n",
       "      <td>0.096738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/c/en/chairperson</th>\n",
       "      <td>-4.212794e-17</td>\n",
       "      <td>6.804785e-16</td>\n",
       "      <td>1.320734e-17</td>\n",
       "      <td>1.889603e-07</td>\n",
       "      <td>-2.959769e-07</td>\n",
       "      <td>6.120348e-08</td>\n",
       "      <td>-6.157436e-16</td>\n",
       "      <td>-6.563820e-16</td>\n",
       "      <td>-3.615849e-16</td>\n",
       "      <td>1.146372e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027895</td>\n",
       "      <td>0.026888</td>\n",
       "      <td>-0.036298</td>\n",
       "      <td>-0.048417</td>\n",
       "      <td>-0.049670</td>\n",
       "      <td>-0.051038</td>\n",
       "      <td>-0.049078</td>\n",
       "      <td>-0.043156</td>\n",
       "      <td>-0.058154</td>\n",
       "      <td>0.091190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/c/en/chair</th>\n",
       "      <td>-8.906453e-17</td>\n",
       "      <td>6.522849e-16</td>\n",
       "      <td>-2.717981e-17</td>\n",
       "      <td>1.983456e-07</td>\n",
       "      <td>-3.106775e-07</td>\n",
       "      <td>6.424335e-08</td>\n",
       "      <td>-8.001632e-16</td>\n",
       "      <td>-1.145839e-16</td>\n",
       "      <td>-6.617410e-16</td>\n",
       "      <td>2.461867e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029281</td>\n",
       "      <td>0.028224</td>\n",
       "      <td>-0.038101</td>\n",
       "      <td>-0.050822</td>\n",
       "      <td>-0.052137</td>\n",
       "      <td>-0.053573</td>\n",
       "      <td>-0.051516</td>\n",
       "      <td>-0.045300</td>\n",
       "      <td>-0.061043</td>\n",
       "      <td>0.095720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/c/en/chairperson/n</th>\n",
       "      <td>-9.113447e-17</td>\n",
       "      <td>6.594680e-16</td>\n",
       "      <td>-2.027064e-17</td>\n",
       "      <td>1.867658e-07</td>\n",
       "      <td>-2.925395e-07</td>\n",
       "      <td>6.049270e-08</td>\n",
       "      <td>-7.669644e-16</td>\n",
       "      <td>-2.256429e-16</td>\n",
       "      <td>-6.009574e-16</td>\n",
       "      <td>2.290223e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027571</td>\n",
       "      <td>0.026576</td>\n",
       "      <td>-0.035877</td>\n",
       "      <td>-0.047855</td>\n",
       "      <td>-0.049093</td>\n",
       "      <td>-0.050446</td>\n",
       "      <td>-0.048508</td>\n",
       "      <td>-0.042655</td>\n",
       "      <td>-0.057479</td>\n",
       "      <td>0.090131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/c/en/president/n/wn/person</th>\n",
       "      <td>2.159347e-15</td>\n",
       "      <td>-3.783949e-16</td>\n",
       "      <td>-5.054159e-15</td>\n",
       "      <td>1.601425e-07</td>\n",
       "      <td>-2.508382e-07</td>\n",
       "      <td>5.186957e-08</td>\n",
       "      <td>-3.338260e-15</td>\n",
       "      <td>-2.859790e-16</td>\n",
       "      <td>3.288175e-15</td>\n",
       "      <td>4.581335e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023641</td>\n",
       "      <td>0.022788</td>\n",
       "      <td>-0.030763</td>\n",
       "      <td>-0.041033</td>\n",
       "      <td>-0.042095</td>\n",
       "      <td>-0.043255</td>\n",
       "      <td>-0.041593</td>\n",
       "      <td>-0.036575</td>\n",
       "      <td>-0.049285</td>\n",
       "      <td>0.077283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      0             1             2    \\\n",
       "/c/en/chair_meeting         -4.221157e-17  6.753685e-16  1.230684e-17   \n",
       "/c/en/chairperson           -4.212794e-17  6.804785e-16  1.320734e-17   \n",
       "/c/en/chair                 -8.906453e-17  6.522849e-16 -2.717981e-17   \n",
       "/c/en/chairperson/n         -9.113447e-17  6.594680e-16 -2.027064e-17   \n",
       "/c/en/president/n/wn/person  2.159347e-15 -3.783949e-16 -5.054159e-15   \n",
       "\n",
       "                                      3             4             5    \\\n",
       "/c/en/chair_meeting          2.004569e-07 -3.139845e-07  6.492718e-08   \n",
       "/c/en/chairperson            1.889603e-07 -2.959769e-07  6.120348e-08   \n",
       "/c/en/chair                  1.983456e-07 -3.106775e-07  6.424335e-08   \n",
       "/c/en/chairperson/n          1.867658e-07 -2.925395e-07  6.049270e-08   \n",
       "/c/en/president/n/wn/person  1.601425e-07 -2.508382e-07  5.186957e-08   \n",
       "\n",
       "                                      6             7             8    \\\n",
       "/c/en/chair_meeting         -5.941687e-16 -7.451524e-16 -3.245492e-16   \n",
       "/c/en/chairperson           -6.157436e-16 -6.563820e-16 -3.615849e-16   \n",
       "/c/en/chair                 -8.001632e-16 -1.145839e-16 -6.617410e-16   \n",
       "/c/en/chairperson/n         -7.669644e-16 -2.256429e-16 -6.009574e-16   \n",
       "/c/en/president/n/wn/person -3.338260e-15 -2.859790e-16  3.288175e-15   \n",
       "\n",
       "                                      9    ...       290       291       292  \\\n",
       "/c/en/chair_meeting          1.050718e-16  ... -0.029592  0.028524 -0.038507   \n",
       "/c/en/chairperson            1.146372e-16  ... -0.027895  0.026888 -0.036298   \n",
       "/c/en/chair                  2.461867e-16  ... -0.029281  0.028224 -0.038101   \n",
       "/c/en/chairperson/n          2.290223e-16  ... -0.027571  0.026576 -0.035877   \n",
       "/c/en/president/n/wn/person  4.581335e-15  ... -0.023641  0.022788 -0.030763   \n",
       "\n",
       "                                  293       294       295       296       297  \\\n",
       "/c/en/chair_meeting         -0.051363 -0.052692 -0.054144 -0.052064 -0.045782   \n",
       "/c/en/chairperson           -0.048417 -0.049670 -0.051038 -0.049078 -0.043156   \n",
       "/c/en/chair                 -0.050822 -0.052137 -0.053573 -0.051516 -0.045300   \n",
       "/c/en/chairperson/n         -0.047855 -0.049093 -0.050446 -0.048508 -0.042655   \n",
       "/c/en/president/n/wn/person -0.041033 -0.042095 -0.043255 -0.041593 -0.036575   \n",
       "\n",
       "                                  298       299  \n",
       "/c/en/chair_meeting         -0.061692  0.096738  \n",
       "/c/en/chairperson           -0.058154  0.091190  \n",
       "/c/en/chair                 -0.061043  0.095720  \n",
       "/c/en/chairperson/n         -0.057479  0.090131  \n",
       "/c/en/president/n/wn/person -0.049285  0.077283  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embedding = load_hdf(\"data/conceptnet_api/retrofit/test_retrofitted\")\n",
    "input_embedding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.2211573e-17,  6.7536854e-16,  1.2306839e-17, ...,\n",
       "        -4.5781989e-02, -6.1692268e-02,  9.6738428e-02],\n",
       "       [-4.2127938e-17,  6.8047853e-16,  1.3207345e-17, ...,\n",
       "        -4.3156303e-02, -5.8154099e-02,  9.1190293e-02],\n",
       "       [-8.9064528e-17,  6.5228493e-16, -2.7179813e-17, ...,\n",
       "        -4.5299806e-02, -6.1042514e-02,  9.5719561e-02],\n",
       "       ...,\n",
       "       [ 7.7134235e-17,  9.1936533e-17,  3.2419220e-16, ...,\n",
       "        -4.3782692e-02, -5.8998175e-02,  9.2513867e-02],\n",
       "       [ 7.0881557e-17,  8.9736795e-17,  3.1857404e-16, ...,\n",
       "        -4.3782692e-02, -5.8998175e-02,  9.2513867e-02],\n",
       "       [ 9.9147145e-17,  9.2629253e-17,  3.3545909e-16, ...,\n",
       "        -4.3782692e-02, -5.8998175e-02,  9.2513867e-02]],\n",
       "      shape=(4081, 300), dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_array = input_embedding.to_numpy()\n",
    "embedding_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 593,  595,  590, ..., 2518, 2514, 2516], shape=(4081,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_labels_to_int(labels):\n",
    "    \"\"\"\n",
    "    Convert various label formats to integer labels\n",
    "    \n",
    "    Args:\n",
    "        labels: Could be strings, one-hot, etc.\n",
    "    \n",
    "    Returns:\n",
    "        numpy array of integer labels\n",
    "    \"\"\"\n",
    "    if isinstance(labels[0], str):\n",
    "        # String labels to integers\n",
    "        unique_labels = sorted(set(labels))\n",
    "        label_to_int = {label: i for i, label in enumerate(unique_labels)}\n",
    "        return np.array([label_to_int[label] for label in labels])\n",
    "    elif len(labels.shape) > 1 and labels.shape[1] > 1:\n",
    "        # One-hot to integers\n",
    "        return np.argmax(labels, axis=1)\n",
    "    else:\n",
    "        # Already integers or binary\n",
    "        return labels.astype(int)\n",
    "    \n",
    "labels = convert_labels_to_int(input_embedding.index.to_list())\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embeddings: Pre-computed embeddings (numpy array or torch tensor)\n",
    "                       Shape: (num_samples, seq_length, embedding_dim)\n",
    "            labels: Corresponding labels\n",
    "        \"\"\"\n",
    "        self.embeddings = torch.tensor(embeddings, dtype=torch.float)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_embeddings': self.embeddings[idx],\n",
    "            'labels': self.labels[idx]\n",
    "        }\n",
    "    \n",
    "dataset = EmbeddingDataset(embedding_array, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingConfig(PretrainedConfig):\n",
    "    def __init__(self, embedding_dim=300, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "class EmbeddingModel(PreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.transformer = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.classifier = nn.Linear(config.embedding_dim, config.num_labels)\n",
    "        \n",
    "    def forward(self, input_embeddings, attention_mask=None, labels=None):\n",
    "        # Bypass the embedding layer and use pre-computed embeddings\n",
    "        outputs = self.transformer(\n",
    "            inputs_embeds=input_embeddings,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "        # Use [CLS] token for classification\n",
    "        logits = self.classifier(outputs.last_hidden_state[:, 0, :])\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(logits.view(-1, self.config.num_labels), labels.view(-1))\n",
    "            \n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'logits': logits,\n",
    "            'hidden_states': outputs.hidden_states\n",
    "        }\n",
    "\n",
    "# Initialize model\n",
    "config = EmbeddingConfig(embedding_dim=300, num_labels=4081)\n",
    "model = EmbeddingModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m inputs = batch[\u001b[33m'\u001b[39m\u001b[33minput_embeddings\u001b[39m\u001b[33m'\u001b[39m].to(device)\n\u001b[32m     13\u001b[39m labels = batch[\u001b[33m'\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m'\u001b[39m].to(device)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m loss = outputs[\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     17\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cs4248_project/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cs4248_project/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mEmbeddingModel.forward\u001b[39m\u001b[34m(self, input_embeddings, attention_mask, labels)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_embeddings, attention_mask=\u001b[38;5;28;01mNone\u001b[39;00m, labels=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     13\u001b[39m     \u001b[38;5;66;03m# Bypass the embedding layer and use pre-computed embeddings\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m     \u001b[38;5;66;03m# Use [CLS] token for classification\u001b[39;00m\n\u001b[32m     20\u001b[39m     logits = \u001b[38;5;28mself\u001b[39m.classifier(outputs.last_hidden_state[:, \u001b[32m0\u001b[39m, :])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cs4248_project/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cs4248_project/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/cs4248_project/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:1064\u001b[39m, in \u001b[36mBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1061\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1062\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou have to specify either input_ids or inputs_embeds\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1064\u001b[39m batch_size, seq_length = input_shape\n\u001b[32m   1065\u001b[39m device = input_ids.device \u001b[38;5;28;01mif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m inputs_embeds.device\n\u001b[32m   1067\u001b[39m \u001b[38;5;66;03m# past_key_values_length\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(3):\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        inputs = batch['input_embeddings'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_embeddings=inputs, labels=labels)\n",
    "        loss = outputs['loss']\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f\"Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def _prepare_inputs(self, inputs):\n",
    "        prepared = {}\n",
    "        for k, v in inputs.items():\n",
    "            if k == 'input_embeddings':\n",
    "                prepared['inputs_embeds'] = v.to(self.args.device)\n",
    "            elif isinstance(v, torch.Tensor):\n",
    "                prepared[k] = v.to(self.args.device)\n",
    "            else:\n",
    "                prepared[k] = v\n",
    "        return prepared\n",
    "\n",
    "# Usage with TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./embedding_results\",\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    ")\n",
    "\n",
    "trainer = EmbeddingTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs4248_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
