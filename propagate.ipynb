{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" uri.py\n",
    "URIs are Unicode strings that represent the canonical name for any object in\n",
    "ConceptNet. These can be used with the ConceptNet Web API, or referred to in a\n",
    "Semantic Web application, by attaching the prefix:\n",
    "\n",
    "    http://api.conceptnet.io\n",
    "\n",
    "For example, the English concept \"book\" has the URI '/c/en/book'. This concept\n",
    "can be referred to, or retrieved, using this complete URI:\n",
    "\n",
    "    http://api.conceptnet.io/c/en/book\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def standardize_text(text, lowercase=True):\n",
    "    raise NotImplementedError(\n",
    "        \"This function has been superseded by \"\n",
    "        \"conceptnet5.nodes.preprocess_and_tokenize_text.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def join_uri(*pieces):\n",
    "    \"\"\"\n",
    "    `join_uri` builds a URI from constituent pieces that should be joined with\n",
    "    slashes (/).\n",
    "\n",
    "    Leading and trailing on the pieces are acceptable, but will be ignored. The\n",
    "    resulting URI will always begin with a slash and have its pieces separated\n",
    "    by a single slash.\n",
    "\n",
    "    The pieces do not have `preprocess_and_tokenize_text` applied to them; to\n",
    "    make sure your URIs are in normal form, run `preprocess_and_tokenize_text`\n",
    "    on each piece that represents arbitrary text.\n",
    "\n",
    "    >>> join_uri('/c', 'en', 'cat')\n",
    "    '/c/en/cat'\n",
    "\n",
    "    >>> join_uri('c', 'en', ' spaces ')\n",
    "    '/c/en/ spaces '\n",
    "\n",
    "    >>> join_uri('/r/', 'AtLocation/')\n",
    "    '/r/AtLocation'\n",
    "\n",
    "    >>> join_uri('/test')\n",
    "    '/test'\n",
    "\n",
    "    >>> join_uri('test')\n",
    "    '/test'\n",
    "\n",
    "    >>> join_uri('/test', '/more/')\n",
    "    '/test/more'\n",
    "    \"\"\"\n",
    "    joined = '/' + ('/'.join([piece.strip('/') for piece in pieces]))\n",
    "    return joined\n",
    "\n",
    "\n",
    "def concept_uri(lang, text, *more):\n",
    "    \"\"\"\n",
    "    `concept_uri` builds a representation of a concept, which is a word or\n",
    "    phrase of a particular language, which can participate in relations with\n",
    "    other concepts, and may be linked to concepts in other languages.\n",
    "\n",
    "    Every concept has an ISO language code and a text. It may also have a part\n",
    "    of speech (pos), which is typically a single letter. If it does, it may\n",
    "    have a disambiguation, a string that distinguishes it from other concepts\n",
    "    with the same text.\n",
    "\n",
    "    This function should be called as follows, where arguments after `text`\n",
    "    are optional:\n",
    "\n",
    "        concept_uri(lang, text, pos, disambiguation...)\n",
    "\n",
    "    `text` and `disambiguation` should be strings that have already been run\n",
    "    through `preprocess_and_tokenize_text`.\n",
    "\n",
    "    This is a low-level interface. See `standardized_concept_uri` in nodes.py for\n",
    "    a more generally applicable function that also deals with special\n",
    "    per-language handling.\n",
    "\n",
    "    >>> concept_uri('en', 'cat')\n",
    "    '/c/en/cat'\n",
    "    >>> concept_uri('en', 'cat', 'n')\n",
    "    '/c/en/cat/n'\n",
    "    >>> concept_uri('en', 'cat', 'n', 'feline')\n",
    "    '/c/en/cat/n/feline'\n",
    "    >>> concept_uri('en', 'this is wrong')\n",
    "    Traceback (most recent call last):\n",
    "        ...\n",
    "    AssertionError: 'this is wrong' is not in normalized form\n",
    "    \"\"\"\n",
    "    assert ' ' not in text, \"%r is not in normalized form\" % text\n",
    "    if len(more) > 0:\n",
    "        if len(more[0]) != 1:\n",
    "            # We misparsed a part of speech; everything after the text is\n",
    "            # probably junk\n",
    "            more = []\n",
    "        for dis1 in more[1:]:\n",
    "            assert ' ' not in dis1, \"%r is not in normalized form\" % dis1\n",
    "\n",
    "    return join_uri('/c', lang, text, *more)\n",
    "\n",
    "\n",
    "def compound_uri(op, args):\n",
    "    \"\"\"\n",
    "    Some URIs represent a compound structure or operator built out of a number\n",
    "    of arguments. Some examples are the '/and' and '/or' operators, which\n",
    "    represent a conjunction or disjunction over two or more URIs, which may\n",
    "    themselves be compound URIs; or the assertion structure, '/a', which takes\n",
    "    a relation and two URIs as its arguments.\n",
    "\n",
    "    This function takes the main 'operator', with the slash included, and an\n",
    "    arbitrary number of arguments, and produces the URI that represents the\n",
    "    entire compound structure.\n",
    "\n",
    "    These structures contain square brackets as segments, which look like\n",
    "    `/[/` and `/]/`, so that compound URIs can contain other compound URIs\n",
    "    without ambiguity.\n",
    "\n",
    "    >>> compound_uri('/nothing', [])\n",
    "    '/nothing/[/]'\n",
    "    >>> compound_uri('/a', ['/r/CapableOf', '/c/en/cat', '/c/en/sleep'])\n",
    "    '/a/[/r/CapableOf/,/c/en/cat/,/c/en/sleep/]'\n",
    "    \"\"\"\n",
    "    items = [op]\n",
    "    first_item = True\n",
    "    items.append('[')\n",
    "    for arg in args:\n",
    "        if first_item:\n",
    "            first_item = False\n",
    "        else:\n",
    "            items.append(',')\n",
    "        items.append(arg)\n",
    "    items.append(']')\n",
    "    return join_uri(*items)\n",
    "\n",
    "\n",
    "def split_uri(uri):\n",
    "    \"\"\"\n",
    "    Get the slash-delimited pieces of a URI.\n",
    "\n",
    "    >>> split_uri('/c/en/cat/n/animal')\n",
    "    ['c', 'en', 'cat', 'n', 'animal']\n",
    "    >>> split_uri('/')\n",
    "    []\n",
    "    \"\"\"\n",
    "    if not uri.startswith('/'):\n",
    "        return [uri]\n",
    "    uri2 = uri.lstrip('/')\n",
    "    if not uri2:\n",
    "        return []\n",
    "    return uri2.split('/')\n",
    "\n",
    "\n",
    "def uri_prefix(uri, max_pieces=3):\n",
    "    \"\"\"\n",
    "    Strip off components that might make a ConceptNet URI too detailed. Only\n",
    "    the first `max_pieces` components will be kept.\n",
    "\n",
    "    By default, `max_pieces` is 3, making this function useful for converting\n",
    "    disambiguated concepts into their more general ambiguous forms.\n",
    "\n",
    "    If the URI is actually a fully qualified URL, no components are removed.\n",
    "\n",
    "    >>> uri_prefix('/c/en/cat/n/animal')\n",
    "    '/c/en/cat'\n",
    "    >>> uri_prefix('/c/en/cat/n')\n",
    "    '/c/en/cat'\n",
    "    >>> uri_prefix('/c/en/cat')\n",
    "    '/c/en/cat'\n",
    "    >>> uri_prefix('/c/en')\n",
    "    '/c/en'\n",
    "    >>> uri_prefix('/c/en/cat', 2)\n",
    "    '/c/en'\n",
    "    >>> uri_prefix('http://en.wikipedia.org/wiki/Example')\n",
    "    'http://en.wikipedia.org/wiki/Example'\n",
    "    \"\"\"\n",
    "    if is_absolute_url(uri):\n",
    "        return uri\n",
    "    pieces = split_uri(uri)[:max_pieces]\n",
    "    return join_uri(*pieces)\n",
    "\n",
    "\n",
    "def uri_prefixes(uri, min_pieces=2):\n",
    "    \"\"\"\n",
    "    Get URIs that are prefixes of a given URI: that is, they begin with the\n",
    "    same path components. By default, the prefix must have at least 2\n",
    "    components.\n",
    "\n",
    "    If the URI has sub-parts that are grouped by square brackets, then\n",
    "    only complete sub-parts will be allowed in prefixes.\n",
    "\n",
    "    >>> list(uri_prefixes('/c/en/cat/n/animal'))\n",
    "    ['/c/en', '/c/en/cat', '/c/en/cat/n', '/c/en/cat/n/animal']\n",
    "    >>> list(uri_prefixes('/test/[/group/one/]/[/group/two/]'))\n",
    "    ['/test/[/group/one/]', '/test/[/group/one/]/[/group/two/]']\n",
    "    >>> list(uri_prefixes('http://en.wikipedia.org/wiki/Example'))\n",
    "    ['http://en.wikipedia.org/wiki/Example']\n",
    "    \"\"\"\n",
    "    if is_absolute_url(uri):\n",
    "        return [uri]\n",
    "    pieces = []\n",
    "    prefixes = []\n",
    "    for piece in split_uri(uri):\n",
    "        pieces.append(piece)\n",
    "        if len(pieces) >= min_pieces:\n",
    "            if pieces.count('[') == pieces.count(']'):\n",
    "                prefixes.append(join_uri(*pieces))\n",
    "    return prefixes\n",
    "\n",
    "\n",
    "def parse_compound_uri(uri):\n",
    "    \"\"\"\n",
    "    Given a compound URI, extract its operator and its list of arguments.\n",
    "\n",
    "    >>> parse_compound_uri('/nothing/[/]')\n",
    "    ('/nothing', [])\n",
    "    >>> parse_compound_uri('/a/[/r/CapableOf/,/c/en/cat/,/c/en/sleep/]')\n",
    "    ('/a', ['/r/CapableOf', '/c/en/cat', '/c/en/sleep'])\n",
    "    >>> parse_compound_uri('/or/[/and/[/s/one/,/s/two/]/,/and/[/s/three/,/s/four/]/]')\n",
    "    ('/or', ['/and/[/s/one/,/s/two/]', '/and/[/s/three/,/s/four/]'])\n",
    "    \"\"\"\n",
    "    pieces = split_uri(uri)\n",
    "    if pieces[-1] != ']':\n",
    "        raise ValueError(\"Compound URIs must end with /]\")\n",
    "    if '[' not in pieces:\n",
    "        raise ValueError(\n",
    "            \"Compound URIs must contain /[/ at the beginning of the argument list\"\n",
    "        )\n",
    "    list_start = pieces.index('[')\n",
    "    op = join_uri(*pieces[:list_start])\n",
    "\n",
    "    chunks = []\n",
    "    current = []\n",
    "    depth = 0\n",
    "\n",
    "    # Split on commas, but not if they're within additional pairs of brackets.\n",
    "    for piece in pieces[(list_start + 1) : -1]:\n",
    "        if piece == ',' and depth == 0:\n",
    "            chunks.append('/' + ('/'.join(current)).strip('/'))\n",
    "            current = []\n",
    "        else:\n",
    "            current.append(piece)\n",
    "            if piece == '[':\n",
    "                depth += 1\n",
    "            elif piece == ']':\n",
    "                depth -= 1\n",
    "\n",
    "    assert depth == 0, \"Unmatched brackets in %r\" % uri\n",
    "    if current:\n",
    "        chunks.append('/' + ('/'.join(current)).strip('/'))\n",
    "    return op, chunks\n",
    "\n",
    "\n",
    "def parse_possible_compound_uri(op, uri):\n",
    "    \"\"\"\n",
    "    The AND and OR conjunctions can be expressed as compound URIs, but if they\n",
    "    contain only one thing, they are returned as just that single URI, not a\n",
    "    compound.\n",
    "\n",
    "    This function returns the list of things in the compound URI if its operator\n",
    "    matches `op`, or a list containing the URI itself if not.\n",
    "\n",
    "    >>> parse_possible_compound_uri(\n",
    "    ...    'or', '/or/[/and/[/s/one/,/s/two/]/,/and/[/s/three/,/s/four/]/]'\n",
    "    ... )\n",
    "    ['/and/[/s/one/,/s/two/]', '/and/[/s/three/,/s/four/]']\n",
    "    >>> parse_possible_compound_uri('or', '/s/contributor/omcs/dev')\n",
    "    ['/s/contributor/omcs/dev']\n",
    "    \"\"\"\n",
    "    if uri.startswith('/' + op + '/'):\n",
    "        return parse_compound_uri(uri)[1]\n",
    "    else:\n",
    "        return [uri]\n",
    "\n",
    "\n",
    "def conjunction_uri(*sources):\n",
    "    \"\"\"\n",
    "    Make a URI representing a conjunction of sources that work together to provide\n",
    "    an assertion. The sources will be sorted in lexicographic order.\n",
    "\n",
    "    >>> conjunction_uri('/s/contributor/omcs/dev')\n",
    "    '/s/contributor/omcs/dev'\n",
    "\n",
    "    >>> conjunction_uri('/s/rule/some_kind_of_parser', '/s/contributor/omcs/dev')\n",
    "    '/and/[/s/contributor/omcs/dev/,/s/rule/some_kind_of_parser/]'\n",
    "    \"\"\"\n",
    "    if len(sources) == 0:\n",
    "        # Logically, a conjunction with 0 inputs represents 'True', a\n",
    "        # proposition that cannot be denied. This could be useful as a\n",
    "        # justification for, say, mathematical axioms, but when it comes to\n",
    "        # ConceptNet, that kind of thing makes us uncomfortable and shouldn't\n",
    "        # appear in the data.\n",
    "        raise ValueError(\"Conjunctions of 0 things are not allowed\")\n",
    "    elif len(sources) == 1:\n",
    "        return sources[0]\n",
    "    else:\n",
    "        return compound_uri('/and', sorted(set(sources)))\n",
    "\n",
    "\n",
    "def assertion_uri(rel, start, end):\n",
    "    \"\"\"\n",
    "    Make a URI for an assertion, as a compound URI of its relation, start node,\n",
    "    and end node.\n",
    "\n",
    "    >>> assertion_uri('/r/CapableOf', '/c/en/cat', '/c/en/sleep')\n",
    "    '/a/[/r/CapableOf/,/c/en/cat/,/c/en/sleep/]'\n",
    "    \"\"\"\n",
    "    assert rel.startswith('/r'), rel\n",
    "    return compound_uri('/a', (rel, start, end))\n",
    "\n",
    "\n",
    "def is_concept(uri):\n",
    "    \"\"\"\n",
    "    >>> is_concept('/c/sv/klänning')\n",
    "    True\n",
    "    >>> is_concept('/x/en/ly')\n",
    "    False\n",
    "    >>> is_concept('/a/[/r/Synonym/,/c/ro/funcția_beta/,/c/en/beta_function/]')\n",
    "    False\n",
    "    \"\"\"\n",
    "    return uri.startswith('/c/')\n",
    "\n",
    "\n",
    "def is_relation(uri):\n",
    "    \"\"\"\n",
    "    >>> is_relation('/r/IsA')\n",
    "    True\n",
    "    >>> is_relation('/c/sv/klänning')\n",
    "    False\n",
    "    \"\"\"\n",
    "    return uri.startswith('/r/')\n",
    "\n",
    "\n",
    "def is_term(uri):\n",
    "    \"\"\"\n",
    "    >>> is_term('/c/sv/kostym')\n",
    "    True\n",
    "    >>> is_term('/x/en/ify')\n",
    "    True\n",
    "    >>> is_term('/a/[/r/RelatedTo/,/c/en/cake/,/c/en/flavor/]')\n",
    "    False\n",
    "    \"\"\"\n",
    "    return uri.startswith('/c/') or uri.startswith('/x/')\n",
    "\n",
    "\n",
    "def is_absolute_url(uri):\n",
    "    \"\"\"\n",
    "    We have URLs pointing to Creative Commons licenses, starting with 'cc:',\n",
    "    which for Linked Data purposes are absolute URLs because they'll be resolved\n",
    "    into full URLs.\n",
    "\n",
    "    >>> is_absolute_url('http://fr.wiktionary.org/wiki/mįkká’e_uxpáðe')\n",
    "    True\n",
    "    >>> is_absolute_url('/c/fr/nouveau')\n",
    "    False\n",
    "    \"\"\"\n",
    "    return uri.startswith('http') or uri.startswith('cc:')\n",
    "\n",
    "\n",
    "def get_uri_language(uri):\n",
    "    \"\"\"\n",
    "    Extract the language from a concept URI. If the URI points to an assertion,\n",
    "    get the language of its first concept.\n",
    "\n",
    "    >>> get_uri_language('/a/[/r/RelatedTo/,/c/en/orchestra/,/c/en/symphony/]')\n",
    "    'en'\n",
    "    >>> get_uri_language('/c/pl/cześć')\n",
    "    'pl'\n",
    "    >>> get_uri_language('/x/en/able')\n",
    "    'en'\n",
    "    \"\"\"\n",
    "    if uri.startswith('/a/'):\n",
    "        return get_uri_language(parse_possible_compound_uri('a', uri)[1])\n",
    "    elif is_term(uri):\n",
    "        return split_uri(uri)[1]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def uri_to_label(uri):\n",
    "    \"\"\"\n",
    "    Convert a ConceptNet uri into a label to be used in nodes. This function\n",
    "    replaces an underscore with a space, so while '/c/en/example' will be\n",
    "    converted into 'example', '/c/en/canary_islands' will be converted into\n",
    "    'canary islands'.\n",
    "\n",
    "    >>> uri_to_label('/c/en/example')\n",
    "    'example'\n",
    "    >>> uri_to_label('/c/en/canary_islands')\n",
    "    'canary islands'\n",
    "    >>> uri_to_label('/c/en')\n",
    "    ''\n",
    "    >>> uri_to_label('/r/RelatedTo')\n",
    "    'RelatedTo'\n",
    "    >>> uri_to_label('http://wikidata.dbpedia.org/resource/Q89')\n",
    "    'Q89'\n",
    "    \"\"\"\n",
    "    if is_absolute_url(uri):\n",
    "        return uri.split('/')[-1].replace('_', ' ')\n",
    "    if is_term(uri):\n",
    "        uri = uri_prefix(uri)\n",
    "    parts = split_uri(uri)\n",
    "    if len(parts) < 3 and not is_relation(uri):\n",
    "        return ''\n",
    "    return parts[-1].replace('_', ' ')\n",
    "\n",
    "\n",
    "class Licenses:\n",
    "    cc_attribution = 'cc:by/4.0'\n",
    "    cc_sharealike = 'cc:by-sa/4.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "import numpy as np\n",
    "import re \n",
    "from collections import defaultdict\n",
    "import csv\n",
    "\n",
    "\n",
    "class SparseMatrixBuilder:\n",
    "    \"\"\"\n",
    "    SparseMatrixBuilder is a utility class that helps build a matrix of\n",
    "    unknown shape.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.row_index = []\n",
    "        self.col_index = []\n",
    "        self.values = []\n",
    "\n",
    "    def __setitem__(self, key, val):\n",
    "        row, col = key\n",
    "        self.add(row, col, val)\n",
    "\n",
    "    def add(self, row, col, val):\n",
    "        self.row_index.append(row)\n",
    "        self.col_index.append(col)\n",
    "        self.values.append(val)\n",
    "\n",
    "    def tocsr(self, shape, dtype=float):\n",
    "        return sparse.coo_matrix(\n",
    "            (self.values, (self.row_index, self.col_index)), shape=shape, dtype=dtype\n",
    "        ).tocsr()\n",
    "DOUBLE_DIGIT_RE = re.compile(r'[0-9][0-9]')\n",
    "DIGIT_RE = re.compile(r'[0-9]')\n",
    "def replace_numbers(s):\n",
    "    \"\"\"\n",
    "    Replace digits with # in any term where a sequence of two digits appears.\n",
    "\n",
    "    This operation is applied to text that passes through word2vec, so we\n",
    "    should match it.\n",
    "    \"\"\"\n",
    "    if DOUBLE_DIGIT_RE.search(s):\n",
    "        return DIGIT_RE.sub('#', s)\n",
    "    else:\n",
    "        return s\n",
    " \n",
    "def concept_is_bad(uri):\n",
    "    \"\"\"\n",
    "    Skip concepts that are unlikely to be useful.\n",
    "\n",
    "    A concept containing too many underscores is probably a long, overly\n",
    "    specific phrase, possibly mis-parsed. A concept with a colon is probably\n",
    "    detritus from a wiki.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        ':' in uri\n",
    "        or uri.count('_') >= 3\n",
    "        or uri.startswith('/a/')\n",
    "        or uri.count('/') <= 2\n",
    "    )\n",
    "def is_negative_relation(rel):\n",
    "    \"\"\"\n",
    "    Negative relations describe ways that concepts are different or unrelated.\n",
    "    In cases where we our goal is to determine how related concepts are, such\n",
    "    as conceptnet5.builders.reduce_assoc, we should disregard negative\n",
    "    relations.\n",
    "    \"\"\"\n",
    "    return rel.startswith('/r/Not') or rel == '/r/Antonym' or rel == '/r/DistinctFrom'\n",
    "class ConceptNetAssociationGraph:\n",
    "    '''\n",
    "    Class to hold the concept-association edge graph.\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        '''Construct a graph with no vertices or edges.'''\n",
    "        self.vertex_to_neighbors = defaultdict(set)\n",
    "\n",
    "    def add_edge(self, left, right, value, dataset, relation):\n",
    "        '''Insert an edge in the graph.'''\n",
    "        self.vertex_to_neighbors[left].add(right)\n",
    "        self.vertex_to_neighbors[right].add(left)\n",
    "        return\n",
    "\n",
    "    def vertices(self):\n",
    "        '''Returns an iterator over the vertices of the graph.'''\n",
    "        return self.vertex_to_neighbors.keys()\n",
    "\n",
    "    def find_components(self):\n",
    "        '''\n",
    "        Returns a dict mapping the vertices of the graph to labels,\n",
    "        such that two vertices map to the same label if and only if\n",
    "        they belong to the same connected component of the undirected\n",
    "        graph obtained by adding the reversal of every edge to the\n",
    "        graph.  (But note that this function does not modify the graph,\n",
    "        i.e. it does not add any edges.)\n",
    "        '''\n",
    "\n",
    "        component_labels = {vertex: -1 for vertex in self.vertices()}\n",
    "        vertices_to_examine = set(self.vertices())\n",
    "        new_label = -1\n",
    "        while len(vertices_to_examine) > 0:\n",
    "            new_label += 1\n",
    "            vertex = vertices_to_examine.pop()\n",
    "            assert component_labels[vertex] == -1\n",
    "            stack = [vertex]\n",
    "            component_labels[vertex] = new_label\n",
    "            while len(stack) > 0:\n",
    "                v = stack.pop()\n",
    "                for neighbor in self.vertex_to_neighbors[v]:\n",
    "                    if component_labels[neighbor] != new_label:\n",
    "                        assert component_labels[neighbor] == -1\n",
    "                        component_labels[neighbor] = new_label\n",
    "                        vertices_to_examine.discard(neighbor)\n",
    "                        stack.append(neighbor)\n",
    "\n",
    "        return component_labels\n",
    "\n",
    "    @classmethod\n",
    "    def from_csv(cls, filename, filtered_concepts=None, reject_negative_relations=True):\n",
    "        \"\"\"\n",
    "        Reads an association file and builds an (undirected) graph from it.\n",
    "\n",
    "        If filtered_concepts isn't None, it should be a collection of concepts,\n",
    "        and only vertices from this collection and edges that link two such\n",
    "        vertices will be added to the graph.  If it _is_ None (the default),\n",
    "        however, please note that no such filtering will be done (i.e. the\n",
    "        effective filter collection is then the universal set of concepts, not\n",
    "        the empty set).\n",
    "\n",
    "        If reject_negative_relations is True (the default), only edges not\n",
    "        corresponding to negative relations will be added to the graph.\n",
    "        \"\"\"\n",
    "        graph = cls()\n",
    "\n",
    "        if filtered_concepts is None:\n",
    "            filter_concepts = False\n",
    "        else:\n",
    "            filter_concepts = True\n",
    "\n",
    "        with open(filename, encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                for row in csv.reader([line]):\n",
    "                    try:\n",
    "                        left = row[0].strip()\n",
    "                        right = row[1].strip()\n",
    "                        value = float(row[2].strip())\n",
    "                        dataset = row[3].strip()\n",
    "                        rel = row[4].strip()\n",
    "                    except (ValueError, IndexError):\n",
    "                        continue\n",
    "\n",
    "                if concept_is_bad(left) or concept_is_bad(right):\n",
    "                    continue\n",
    "                if reject_negative_relations and is_negative_relation(rel):                    \n",
    "                    continue\n",
    "                \n",
    "                fvalue = float(value)\n",
    "                gleft = uri_prefix(left)\n",
    "                gright = uri_prefix(right)\n",
    "                if fvalue == 0:\n",
    "                    continue\n",
    "                if gleft == gright:\n",
    "                    continue\n",
    "                if filter_concepts and gleft not in filtered_concepts:\n",
    "                    continue\n",
    "                if filter_concepts and gright not in filtered_concepts:\n",
    "                    continue\n",
    "                graph.add_edge(gleft, gright, value, dataset, rel)\n",
    "\n",
    "        return graph\n",
    "       \n",
    "class ConceptNetAssociationGraphForPropagation(ConceptNetAssociationGraph):\n",
    "    \"\"\"\n",
    "    Subclass of ConceptNetAssociationGraph specialized for use in making\n",
    "    the full graph of a set of associations as required for propagation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.edges = set()\n",
    "\n",
    "    def add_edge(self, left, right, value, dataset, relation):\n",
    "        \"\"\"\n",
    "        In addition to the superclass's handling of a new edge,\n",
    "        saves the edges as a set of (left, right) pairs.\n",
    "        \"\"\"\n",
    "        # Use URIs that have the additional standardization for vector-space labels,\n",
    "        # replacing sequences of digits with the # sign.\n",
    "        left = replace_numbers(left)\n",
    "        right = replace_numbers(right)\n",
    "        super().add_edge(left, right, value, dataset, relation)\n",
    "        self.edges.add((left, right))\n",
    "        self.edges.add((right, left))  # save undirected edges\n",
    "\n",
    "def make_adjacency_matrix(assoc_filename, embedding_vocab):\n",
    "    \"\"\"\n",
    "    Build a sparse adjacency matrix for the ConceptNet graph presented\n",
    "    in the given assoc file, including all terms from the given embedding\n",
    "    vocabulary and removing all terms from connected components of the graph\n",
    "    that do not overlap that vocabulary.\n",
    "\n",
    "    Also builds an index giving all terms from the resulting joined\n",
    "    graph+embedding vocabulary in the order corresponding to the rows and\n",
    "    columns of the matrix.  Note that it is guaranteed that the terms from\n",
    "    the embedding vocabulary will preceed the remaining terms in that index,\n",
    "    and that among the remaining terms the terms in English will follow all\n",
    "    the others.\n",
    "\n",
    "    Returns the matrix and index, and the number of new English terms.\n",
    "    \"\"\"\n",
    "    # First eliminate all connected components of the graph that don't\n",
    "    # overlap the vocabulary of the embedding; we can't do anything with\n",
    "    # those terms.\n",
    "\n",
    "    graph = ConceptNetAssociationGraphForPropagation.from_csv(\n",
    "        assoc_filename, reject_negative_relations=False\n",
    "    )\n",
    "    component_labels = graph.find_components()\n",
    "\n",
    "    # Get the labels of components that overlap the embedding vocabulary.\n",
    "    good_component_labels = set(\n",
    "        label for term, label in component_labels.items() if term in embedding_vocab\n",
    "    )\n",
    "\n",
    "    # Now get the concepts in those components.\n",
    "    good_concepts = set(\n",
    "        term\n",
    "        for term, label in component_labels.items()\n",
    "        if label in good_component_labels\n",
    "    )\n",
    "\n",
    "    del component_labels, good_component_labels\n",
    "\n",
    "    # Put terms from the embedding first, then terms from the good part\n",
    "    # of the graph neither from the embedding nor in English, then terms\n",
    "    # from the good part of the graph in English but not from the embedding.\n",
    "    #\n",
    "    # (In the corner case where either of these addtional sets of terms is\n",
    "    # empty, construction of a pandas index will fail using generator rather\n",
    "    # than list comprehensions.)\n",
    "    new_vocab = good_concepts - set(embedding_vocab)\n",
    "    good_concepts = embedding_vocab.append(\n",
    "        pd.Index([term for term in new_vocab if get_uri_language(term) != 'en'])\n",
    "    )\n",
    "    n_good_concepts_not_new_en = len(good_concepts)\n",
    "    good_concepts = good_concepts.append(\n",
    "        pd.Index([term for term in new_vocab if get_uri_language(term) == 'en'])\n",
    "    )\n",
    "    del new_vocab\n",
    "    n_new_english = len(good_concepts) - n_good_concepts_not_new_en\n",
    "\n",
    "    good_concepts_map = {term: i for i, term in enumerate(good_concepts)}\n",
    "\n",
    "    # Convert the good part of the graph to an adjacency matrix representation.\n",
    "\n",
    "    # Note: the edges added differ slightly from the way it is done in (e.g.)\n",
    "    # build_from_conceptnet_table (in sparse_matrix_builder.py), in that we\n",
    "    # do not add edges linking specific senses of terms to their more general\n",
    "    # forms (as defined by uri_prefixes).  Currently no such specific senses\n",
    "    # show up in the input to retrofitting (i.e. the output of\n",
    "    # build_from_conceptnet_table), so it doesn't matter, but in the future\n",
    "    # we may want to add such edges here as well.\n",
    "\n",
    "    builder = SparseMatrixBuilder()\n",
    "    for v, w in graph.edges:\n",
    "        try:\n",
    "            index0 = good_concepts_map[v]\n",
    "            index1 = good_concepts_map[w]\n",
    "            builder[index0, index1] = 1\n",
    "        except KeyError:\n",
    "            pass  # one of v, w wasn't good\n",
    "    del graph\n",
    "\n",
    "    adjacency_matrix = builder.tocsr(\n",
    "        shape=(len(good_concepts), len(good_concepts)), dtype=np.int8\n",
    "    )\n",
    "\n",
    "    return adjacency_matrix, good_concepts, n_new_english\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import diags\n",
    "\n",
    "def propagate(\n",
    "    combined_index, embedding, adjacency_matrix, n_new_english, iterations=20\n",
    "):\n",
    "    \"\"\"\n",
    "    For as many non-English terms as possible in the ConceptNet graph whose\n",
    "    edges are presented in the given adjacency matrix (with corresponding term\n",
    "    labels in the given index), find a vector in the target space of the vector\n",
    "    embedding presented in the given embedding file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Propagate the vectors from the embeddings to the remaining\n",
    "    # terms, following the edges of the graph.\n",
    "\n",
    "    embedding_dimension = embedding.values.shape[1]\n",
    "    new_vocab_size = len(combined_index) - embedding.values.shape[0]\n",
    "    vectors = np.vstack(\n",
    "        [\n",
    "            embedding.values,\n",
    "            np.zeros(\n",
    "                (new_vocab_size, embedding_dimension), dtype=embedding.values.dtype\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    for iteration in range(iterations):\n",
    "        zero_indicators = np.abs(vectors).sum(1) == 0\n",
    "        if not np.any(zero_indicators):\n",
    "            break\n",
    "        # Find terms with zero vectors having neighbors with nonzero vectors.\n",
    "        nonzero_indicators = np.logical_not(zero_indicators)\n",
    "        fringe = adjacency_matrix.dot(nonzero_indicators.astype(np.int8)) != 0\n",
    "        fringe = np.logical_and(fringe, zero_indicators)\n",
    "        # Update each as the average of its nonzero neighbors\n",
    "        adjacent_nonzeros = adjacency_matrix[fringe, :].dot(\n",
    "            diags([nonzero_indicators.astype(np.int8)], [0], format='csc')\n",
    "        )\n",
    "        n_adjacent_nonzeros = adjacent_nonzeros.sum(axis=1).A[:, 0]\n",
    "        weights = 1.0 / n_adjacent_nonzeros\n",
    "        vectors[fringe, :] = adjacency_matrix[fringe, :].dot(vectors)\n",
    "        vectors[fringe, :] = diags([weights], [0], format='csr').dot(vectors[fringe, :])\n",
    "\n",
    "    n_old_plus_new_non_en = len(combined_index) - n_new_english\n",
    "    result = pd.DataFrame(\n",
    "        index=combined_index[0:n_old_plus_new_non_en],\n",
    "        data=vectors[0:n_old_plus_new_non_en, :],\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "input_file_path = '../../conceptnet-assertions-5.7.0.csv/assertions.csv'\n",
    "output_file_path = 'filtered_edges.csv'\n",
    "\n",
    "with open(input_file_path, 'r', encoding='utf-8') as infile, open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(['left', 'right', 'value', 'dataset', 'rel'])\n",
    "    \n",
    "    # Read each line of the file\n",
    "    for line in infile:\n",
    "        parts = line.split(\"\t\") \n",
    "        if len(parts) < 2:\n",
    "            continue  \n",
    "        \n",
    "        uri = parts[0] \n",
    "        relation = parts[1]  \n",
    "        start = parts[2] \n",
    "        end =  parts[3] \n",
    "        jsonStruct =  parts[4]      \n",
    "        \n",
    "        if \"/c/en/\" in start or \"/c/en/\" in start:\n",
    "            data = json.loads(jsonStruct)\n",
    "            writer.writerow([start, end, data['weight'], data['dataset'], relation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left</th>\n",
       "      <th>right</th>\n",
       "      <th>value</th>\n",
       "      <th>dataset</th>\n",
       "      <th>rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/c/en/0/n</td>\n",
       "      <td>/c/en/1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/d/wiktionary/fr</td>\n",
       "      <td>/r/Antonym</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/c/en/12_hour_clock/n</td>\n",
       "      <td>/c/en/24_hour_clock</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/d/wiktionary/en</td>\n",
       "      <td>/r/Antonym</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/c/en/24_hour_clock/n</td>\n",
       "      <td>/c/en/12_hour_clock</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/d/wiktionary/en</td>\n",
       "      <td>/r/Antonym</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/c/en/5/n</td>\n",
       "      <td>/c/en/3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/d/wiktionary/en</td>\n",
       "      <td>/r/Antonym</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/c/en/a.c/n</td>\n",
       "      <td>/c/en/d.c</td>\n",
       "      <td>1.0</td>\n",
       "      <td>/d/wiktionary/fr</td>\n",
       "      <td>/r/Antonym</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6356315</th>\n",
       "      <td>/c/en/xerox</td>\n",
       "      <td>/c/en/projector</td>\n",
       "      <td>0.5</td>\n",
       "      <td>/d/dbpedia/en</td>\n",
       "      <td>/r/dbpedia/product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6356316</th>\n",
       "      <td>/c/en/zanella</td>\n",
       "      <td>/c/en/moped</td>\n",
       "      <td>0.5</td>\n",
       "      <td>/d/dbpedia/en</td>\n",
       "      <td>/r/dbpedia/product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6356317</th>\n",
       "      <td>/c/en/zanella</td>\n",
       "      <td>/c/en/motorcycle</td>\n",
       "      <td>0.5</td>\n",
       "      <td>/d/dbpedia/en</td>\n",
       "      <td>/r/dbpedia/product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6356318</th>\n",
       "      <td>/c/en/zara/n/wp/retailer</td>\n",
       "      <td>/c/en/clothing</td>\n",
       "      <td>0.5</td>\n",
       "      <td>/d/dbpedia/en</td>\n",
       "      <td>/r/dbpedia/product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6356319</th>\n",
       "      <td>/c/en/zeeman/n/wp/store</td>\n",
       "      <td>/c/en/clothing</td>\n",
       "      <td>0.5</td>\n",
       "      <td>/d/dbpedia/en</td>\n",
       "      <td>/r/dbpedia/product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6356320 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             left                right  value  \\\n",
       "0                       /c/en/0/n              /c/en/1    1.0   \n",
       "1           /c/en/12_hour_clock/n  /c/en/24_hour_clock    1.0   \n",
       "2           /c/en/24_hour_clock/n  /c/en/12_hour_clock    1.0   \n",
       "3                       /c/en/5/n              /c/en/3    1.0   \n",
       "4                     /c/en/a.c/n            /c/en/d.c    1.0   \n",
       "...                           ...                  ...    ...   \n",
       "6356315               /c/en/xerox      /c/en/projector    0.5   \n",
       "6356316             /c/en/zanella          /c/en/moped    0.5   \n",
       "6356317             /c/en/zanella     /c/en/motorcycle    0.5   \n",
       "6356318  /c/en/zara/n/wp/retailer       /c/en/clothing    0.5   \n",
       "6356319   /c/en/zeeman/n/wp/store       /c/en/clothing    0.5   \n",
       "\n",
       "                  dataset                 rel  \n",
       "0        /d/wiktionary/fr          /r/Antonym  \n",
       "1        /d/wiktionary/en          /r/Antonym  \n",
       "2        /d/wiktionary/en          /r/Antonym  \n",
       "3        /d/wiktionary/en          /r/Antonym  \n",
       "4        /d/wiktionary/fr          /r/Antonym  \n",
       "...                   ...                 ...  \n",
       "6356315     /d/dbpedia/en  /r/dbpedia/product  \n",
       "6356316     /d/dbpedia/en  /r/dbpedia/product  \n",
       "6356317     /d/dbpedia/en  /r/dbpedia/product  \n",
       "6356318     /d/dbpedia/en  /r/dbpedia/product  \n",
       "6356319     /d/dbpedia/en  /r/dbpedia/product  \n",
       "\n",
       "[6356320 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"filtered_edges.csv\",  on_bad_lines='skip')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('out.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hdf(filename):\n",
    "    \"\"\"\n",
    "    Load a semantic vector space from an HDF5 file.\n",
    "\n",
    "    HDF5 is a complex format that can contain many instances of different kinds\n",
    "    of data. The convention we use is that the file contains one labeled\n",
    "    matrix, named \"mat\".\n",
    "    \"\"\"\n",
    "    return pd.read_hdf(filename, 'mat', encoding='utf-8')\n",
    "\n",
    "embedding = load_hdf(\"../test_retrofitted\") \n",
    "embedding_vocab = embedding.index \n",
    "\n",
    "\n",
    "assoc_filename = \"out.csv\"\n",
    "adjacency_matrix, combined_index, n_new_english = make_adjacency_matrix(assoc_filename, embedding_vocab)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2323143x2323143 sparse matrix of type '<class 'numpy.int8'>'\n",
       "\twith 8681854 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/c/en/chair_meeting</th>\n",
       "      <td>-2.129197e-16</td>\n",
       "      <td>-2.004567e-07</td>\n",
       "      <td>3.139843e-07</td>\n",
       "      <td>-6.492713e-08</td>\n",
       "      <td>1.334435e-16</td>\n",
       "      <td>-3.828865e-16</td>\n",
       "      <td>-6.465064e-17</td>\n",
       "      <td>-2.960055e-16</td>\n",
       "      <td>4.203844e-17</td>\n",
       "      <td>-1.789314e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029592</td>\n",
       "      <td>-0.028524</td>\n",
       "      <td>0.038507</td>\n",
       "      <td>-0.051363</td>\n",
       "      <td>0.052692</td>\n",
       "      <td>-0.054144</td>\n",
       "      <td>0.052064</td>\n",
       "      <td>-0.045782</td>\n",
       "      <td>-0.061692</td>\n",
       "      <td>-0.096738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/c/en/chairperson</th>\n",
       "      <td>-2.069472e-16</td>\n",
       "      <td>-1.889602e-07</td>\n",
       "      <td>2.959767e-07</td>\n",
       "      <td>-6.120344e-08</td>\n",
       "      <td>1.127873e-16</td>\n",
       "      <td>-3.864099e-16</td>\n",
       "      <td>-5.233090e-17</td>\n",
       "      <td>-3.366037e-16</td>\n",
       "      <td>3.778755e-17</td>\n",
       "      <td>-2.999062e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027895</td>\n",
       "      <td>-0.026888</td>\n",
       "      <td>0.036298</td>\n",
       "      <td>-0.048417</td>\n",
       "      <td>0.049670</td>\n",
       "      <td>-0.051038</td>\n",
       "      <td>0.049078</td>\n",
       "      <td>-0.043156</td>\n",
       "      <td>-0.058154</td>\n",
       "      <td>-0.091190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/c/en/chair</th>\n",
       "      <td>-2.000913e-16</td>\n",
       "      <td>-1.983455e-07</td>\n",
       "      <td>3.106773e-07</td>\n",
       "      <td>-6.424331e-08</td>\n",
       "      <td>-8.366849e-17</td>\n",
       "      <td>-3.044844e-16</td>\n",
       "      <td>2.726675e-17</td>\n",
       "      <td>-5.378111e-16</td>\n",
       "      <td>2.993259e-17</td>\n",
       "      <td>-9.740842e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029281</td>\n",
       "      <td>-0.028224</td>\n",
       "      <td>0.038101</td>\n",
       "      <td>-0.050822</td>\n",
       "      <td>0.052137</td>\n",
       "      <td>-0.053573</td>\n",
       "      <td>0.051516</td>\n",
       "      <td>-0.045300</td>\n",
       "      <td>-0.061042</td>\n",
       "      <td>-0.095720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/c/en/chairperson/n</th>\n",
       "      <td>-2.004085e-16</td>\n",
       "      <td>-1.867657e-07</td>\n",
       "      <td>2.925394e-07</td>\n",
       "      <td>-6.049266e-08</td>\n",
       "      <td>-5.062227e-17</td>\n",
       "      <td>-3.278182e-16</td>\n",
       "      <td>9.696096e-18</td>\n",
       "      <td>-4.912406e-16</td>\n",
       "      <td>3.229945e-17</td>\n",
       "      <td>-7.964047e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027571</td>\n",
       "      <td>-0.026576</td>\n",
       "      <td>0.035877</td>\n",
       "      <td>-0.047855</td>\n",
       "      <td>0.049093</td>\n",
       "      <td>-0.050446</td>\n",
       "      <td>0.048508</td>\n",
       "      <td>-0.042655</td>\n",
       "      <td>-0.057479</td>\n",
       "      <td>-0.090131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/c/en/president/n/wn/person</th>\n",
       "      <td>-8.483401e-18</td>\n",
       "      <td>-1.530221e-07</td>\n",
       "      <td>2.396853e-07</td>\n",
       "      <td>-4.956326e-08</td>\n",
       "      <td>-7.436574e-16</td>\n",
       "      <td>-6.092042e-15</td>\n",
       "      <td>-8.714433e-16</td>\n",
       "      <td>-4.394232e-15</td>\n",
       "      <td>6.218402e-16</td>\n",
       "      <td>4.450388e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022590</td>\n",
       "      <td>-0.021774</td>\n",
       "      <td>0.029395</td>\n",
       "      <td>-0.039209</td>\n",
       "      <td>0.040223</td>\n",
       "      <td>-0.041332</td>\n",
       "      <td>0.039744</td>\n",
       "      <td>-0.034948</td>\n",
       "      <td>-0.047094</td>\n",
       "      <td>-0.073847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      0             1             2    \\\n",
       "/c/en/chair_meeting         -2.129197e-16 -2.004567e-07  3.139843e-07   \n",
       "/c/en/chairperson           -2.069472e-16 -1.889602e-07  2.959767e-07   \n",
       "/c/en/chair                 -2.000913e-16 -1.983455e-07  3.106773e-07   \n",
       "/c/en/chairperson/n         -2.004085e-16 -1.867657e-07  2.925394e-07   \n",
       "/c/en/president/n/wn/person -8.483401e-18 -1.530221e-07  2.396853e-07   \n",
       "\n",
       "                                      3             4             5    \\\n",
       "/c/en/chair_meeting         -6.492713e-08  1.334435e-16 -3.828865e-16   \n",
       "/c/en/chairperson           -6.120344e-08  1.127873e-16 -3.864099e-16   \n",
       "/c/en/chair                 -6.424331e-08 -8.366849e-17 -3.044844e-16   \n",
       "/c/en/chairperson/n         -6.049266e-08 -5.062227e-17 -3.278182e-16   \n",
       "/c/en/president/n/wn/person -4.956326e-08 -7.436574e-16 -6.092042e-15   \n",
       "\n",
       "                                      6             7             8    \\\n",
       "/c/en/chair_meeting         -6.465064e-17 -2.960055e-16  4.203844e-17   \n",
       "/c/en/chairperson           -5.233090e-17 -3.366037e-16  3.778755e-17   \n",
       "/c/en/chair                  2.726675e-17 -5.378111e-16  2.993259e-17   \n",
       "/c/en/chairperson/n          9.696096e-18 -4.912406e-16  3.229945e-17   \n",
       "/c/en/president/n/wn/person -8.714433e-16 -4.394232e-15  6.218402e-16   \n",
       "\n",
       "                                      9    ...       290       291       292  \\\n",
       "/c/en/chair_meeting         -1.789314e-17  ...  0.029592 -0.028524  0.038507   \n",
       "/c/en/chairperson           -2.999062e-17  ...  0.027895 -0.026888  0.036298   \n",
       "/c/en/chair                 -9.740842e-17  ...  0.029281 -0.028224  0.038101   \n",
       "/c/en/chairperson/n         -7.964047e-17  ...  0.027571 -0.026576  0.035877   \n",
       "/c/en/president/n/wn/person  4.450388e-15  ...  0.022590 -0.021774  0.029395   \n",
       "\n",
       "                                  293       294       295       296       297  \\\n",
       "/c/en/chair_meeting         -0.051363  0.052692 -0.054144  0.052064 -0.045782   \n",
       "/c/en/chairperson           -0.048417  0.049670 -0.051038  0.049078 -0.043156   \n",
       "/c/en/chair                 -0.050822  0.052137 -0.053573  0.051516 -0.045300   \n",
       "/c/en/chairperson/n         -0.047855  0.049093 -0.050446  0.048508 -0.042655   \n",
       "/c/en/president/n/wn/person -0.039209  0.040223 -0.041332  0.039744 -0.034948   \n",
       "\n",
       "                                  298       299  \n",
       "/c/en/chair_meeting         -0.061692 -0.096738  \n",
       "/c/en/chairperson           -0.058154 -0.091190  \n",
       "/c/en/chair                 -0.061042 -0.095720  \n",
       "/c/en/chairperson/n         -0.057479 -0.090131  \n",
       "/c/en/president/n/wn/person -0.047094 -0.073847  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/c/en/chair_meeting</th>\n",
       "      <td>-2.129197e-16</td>\n",
       "      <td>-2.004567e-07</td>\n",
       "      <td>3.139843e-07</td>\n",
       "      <td>-6.492713e-08</td>\n",
       "      <td>1.334435e-16</td>\n",
       "      <td>-3.828865e-16</td>\n",
       "      <td>-6.465064e-17</td>\n",
       "      <td>-2.960055e-16</td>\n",
       "      <td>4.203844e-17</td>\n",
       "      <td>-1.789314e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029592</td>\n",
       "      <td>-0.028524</td>\n",
       "      <td>0.038507</td>\n",
       "      <td>-0.051363</td>\n",
       "      <td>0.052692</td>\n",
       "      <td>-0.054144</td>\n",
       "      <td>0.052064</td>\n",
       "      <td>-0.045782</td>\n",
       "      <td>-0.061692</td>\n",
       "      <td>-0.096738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/c/en/chairperson</th>\n",
       "      <td>-2.069472e-16</td>\n",
       "      <td>-1.889602e-07</td>\n",
       "      <td>2.959767e-07</td>\n",
       "      <td>-6.120344e-08</td>\n",
       "      <td>1.127873e-16</td>\n",
       "      <td>-3.864099e-16</td>\n",
       "      <td>-5.233090e-17</td>\n",
       "      <td>-3.366037e-16</td>\n",
       "      <td>3.778755e-17</td>\n",
       "      <td>-2.999062e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027895</td>\n",
       "      <td>-0.026888</td>\n",
       "      <td>0.036298</td>\n",
       "      <td>-0.048417</td>\n",
       "      <td>0.049670</td>\n",
       "      <td>-0.051038</td>\n",
       "      <td>0.049078</td>\n",
       "      <td>-0.043156</td>\n",
       "      <td>-0.058154</td>\n",
       "      <td>-0.091190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/c/en/chair</th>\n",
       "      <td>-2.000913e-16</td>\n",
       "      <td>-1.983455e-07</td>\n",
       "      <td>3.106773e-07</td>\n",
       "      <td>-6.424331e-08</td>\n",
       "      <td>-8.366849e-17</td>\n",
       "      <td>-3.044844e-16</td>\n",
       "      <td>2.726675e-17</td>\n",
       "      <td>-5.378111e-16</td>\n",
       "      <td>2.993259e-17</td>\n",
       "      <td>-9.740842e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029281</td>\n",
       "      <td>-0.028224</td>\n",
       "      <td>0.038101</td>\n",
       "      <td>-0.050822</td>\n",
       "      <td>0.052137</td>\n",
       "      <td>-0.053573</td>\n",
       "      <td>0.051516</td>\n",
       "      <td>-0.045300</td>\n",
       "      <td>-0.061042</td>\n",
       "      <td>-0.095720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/c/en/chairperson/n</th>\n",
       "      <td>-2.004085e-16</td>\n",
       "      <td>-1.867657e-07</td>\n",
       "      <td>2.925394e-07</td>\n",
       "      <td>-6.049266e-08</td>\n",
       "      <td>-5.062227e-17</td>\n",
       "      <td>-3.278182e-16</td>\n",
       "      <td>9.696096e-18</td>\n",
       "      <td>-4.912406e-16</td>\n",
       "      <td>3.229945e-17</td>\n",
       "      <td>-7.964047e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027571</td>\n",
       "      <td>-0.026576</td>\n",
       "      <td>0.035877</td>\n",
       "      <td>-0.047855</td>\n",
       "      <td>0.049093</td>\n",
       "      <td>-0.050446</td>\n",
       "      <td>0.048508</td>\n",
       "      <td>-0.042655</td>\n",
       "      <td>-0.057479</td>\n",
       "      <td>-0.090131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/c/en/president/n/wn/person</th>\n",
       "      <td>-8.483401e-18</td>\n",
       "      <td>-1.530221e-07</td>\n",
       "      <td>2.396853e-07</td>\n",
       "      <td>-4.956326e-08</td>\n",
       "      <td>-7.436574e-16</td>\n",
       "      <td>-6.092042e-15</td>\n",
       "      <td>-8.714433e-16</td>\n",
       "      <td>-4.394232e-15</td>\n",
       "      <td>6.218402e-16</td>\n",
       "      <td>4.450388e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022590</td>\n",
       "      <td>-0.021774</td>\n",
       "      <td>0.029395</td>\n",
       "      <td>-0.039209</td>\n",
       "      <td>0.040223</td>\n",
       "      <td>-0.041332</td>\n",
       "      <td>0.039744</td>\n",
       "      <td>-0.034948</td>\n",
       "      <td>-0.047094</td>\n",
       "      <td>-0.073847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      0             1             2    \\\n",
       "/c/en/chair_meeting         -2.129197e-16 -2.004567e-07  3.139843e-07   \n",
       "/c/en/chairperson           -2.069472e-16 -1.889602e-07  2.959767e-07   \n",
       "/c/en/chair                 -2.000913e-16 -1.983455e-07  3.106773e-07   \n",
       "/c/en/chairperson/n         -2.004085e-16 -1.867657e-07  2.925394e-07   \n",
       "/c/en/president/n/wn/person -8.483401e-18 -1.530221e-07  2.396853e-07   \n",
       "\n",
       "                                      3             4             5    \\\n",
       "/c/en/chair_meeting         -6.492713e-08  1.334435e-16 -3.828865e-16   \n",
       "/c/en/chairperson           -6.120344e-08  1.127873e-16 -3.864099e-16   \n",
       "/c/en/chair                 -6.424331e-08 -8.366849e-17 -3.044844e-16   \n",
       "/c/en/chairperson/n         -6.049266e-08 -5.062227e-17 -3.278182e-16   \n",
       "/c/en/president/n/wn/person -4.956326e-08 -7.436574e-16 -6.092042e-15   \n",
       "\n",
       "                                      6             7             8    \\\n",
       "/c/en/chair_meeting         -6.465064e-17 -2.960055e-16  4.203844e-17   \n",
       "/c/en/chairperson           -5.233090e-17 -3.366037e-16  3.778755e-17   \n",
       "/c/en/chair                  2.726675e-17 -5.378111e-16  2.993259e-17   \n",
       "/c/en/chairperson/n          9.696096e-18 -4.912406e-16  3.229945e-17   \n",
       "/c/en/president/n/wn/person -8.714433e-16 -4.394232e-15  6.218402e-16   \n",
       "\n",
       "                                      9    ...       290       291       292  \\\n",
       "/c/en/chair_meeting         -1.789314e-17  ...  0.029592 -0.028524  0.038507   \n",
       "/c/en/chairperson           -2.999062e-17  ...  0.027895 -0.026888  0.036298   \n",
       "/c/en/chair                 -9.740842e-17  ...  0.029281 -0.028224  0.038101   \n",
       "/c/en/chairperson/n         -7.964047e-17  ...  0.027571 -0.026576  0.035877   \n",
       "/c/en/president/n/wn/person  4.450388e-15  ...  0.022590 -0.021774  0.029395   \n",
       "\n",
       "                                  293       294       295       296       297  \\\n",
       "/c/en/chair_meeting         -0.051363  0.052692 -0.054144  0.052064 -0.045782   \n",
       "/c/en/chairperson           -0.048417  0.049670 -0.051038  0.049078 -0.043156   \n",
       "/c/en/chair                 -0.050822  0.052137 -0.053573  0.051516 -0.045300   \n",
       "/c/en/chairperson/n         -0.047855  0.049093 -0.050446  0.048508 -0.042655   \n",
       "/c/en/president/n/wn/person -0.039209  0.040223 -0.041332  0.039744 -0.034948   \n",
       "\n",
       "                                  298       299  \n",
       "/c/en/chair_meeting         -0.061692 -0.096738  \n",
       "/c/en/chairperson           -0.058154 -0.091190  \n",
       "/c/en/chair                 -0.061042 -0.095720  \n",
       "/c/en/chairperson/n         -0.057479 -0.090131  \n",
       "/c/en/president/n/wn/person -0.047094 -0.073847  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = propagate(\n",
    "    combined_index, embedding, adjacency_matrix, n_new_english, iterations=20\n",
    ")\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/c/de/verflechten</th>\n",
       "      <td>1.165642e-16</td>\n",
       "      <td>-1.401300e-06</td>\n",
       "      <td>-1.964500e-07</td>\n",
       "      <td>1.257201e-07</td>\n",
       "      <td>1.929672e-16</td>\n",
       "      <td>-1.420060e-16</td>\n",
       "      <td>-1.816806e-16</td>\n",
       "      <td>-9.991165e-18</td>\n",
       "      <td>7.599815e-18</td>\n",
       "      <td>6.863060e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030874</td>\n",
       "      <td>-0.029182</td>\n",
       "      <td>0.022136</td>\n",
       "      <td>-0.040591</td>\n",
       "      <td>0.045733</td>\n",
       "      <td>-0.055873</td>\n",
       "      <td>0.054786</td>\n",
       "      <td>-0.048652</td>\n",
       "      <td>-0.064684</td>\n",
       "      <td>-0.101985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/c/gd/tost_geal</th>\n",
       "      <td>1.987298e-16</td>\n",
       "      <td>3.377577e-05</td>\n",
       "      <td>-1.186720e-05</td>\n",
       "      <td>1.642879e-05</td>\n",
       "      <td>-7.791531e-15</td>\n",
       "      <td>5.764029e-15</td>\n",
       "      <td>6.711658e-15</td>\n",
       "      <td>7.940348e-15</td>\n",
       "      <td>-1.166029e-15</td>\n",
       "      <td>3.713360e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051047</td>\n",
       "      <td>-0.042544</td>\n",
       "      <td>0.031218</td>\n",
       "      <td>0.114923</td>\n",
       "      <td>0.018571</td>\n",
       "      <td>-0.042055</td>\n",
       "      <td>0.052759</td>\n",
       "      <td>-0.043115</td>\n",
       "      <td>-0.061147</td>\n",
       "      <td>-0.036493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/c/ru/осторожный</th>\n",
       "      <td>-6.373484e-17</td>\n",
       "      <td>-7.143095e-07</td>\n",
       "      <td>2.947653e-06</td>\n",
       "      <td>7.169659e-07</td>\n",
       "      <td>3.828752e-16</td>\n",
       "      <td>-4.195293e-17</td>\n",
       "      <td>-2.410384e-16</td>\n",
       "      <td>-5.321990e-16</td>\n",
       "      <td>3.760020e-16</td>\n",
       "      <td>-5.890107e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004821</td>\n",
       "      <td>-0.034773</td>\n",
       "      <td>0.035106</td>\n",
       "      <td>0.027656</td>\n",
       "      <td>0.046567</td>\n",
       "      <td>-0.000695</td>\n",
       "      <td>0.053960</td>\n",
       "      <td>0.195646</td>\n",
       "      <td>-0.041995</td>\n",
       "      <td>-0.098684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/c/tr/acil</th>\n",
       "      <td>8.302191e-17</td>\n",
       "      <td>4.772473e-06</td>\n",
       "      <td>4.615884e-06</td>\n",
       "      <td>-2.601526e-07</td>\n",
       "      <td>-2.876905e-15</td>\n",
       "      <td>1.288548e-15</td>\n",
       "      <td>2.358437e-15</td>\n",
       "      <td>-9.990318e-16</td>\n",
       "      <td>4.368428e-16</td>\n",
       "      <td>-1.655957e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031403</td>\n",
       "      <td>0.003131</td>\n",
       "      <td>0.033343</td>\n",
       "      <td>0.048443</td>\n",
       "      <td>0.039941</td>\n",
       "      <td>-0.045000</td>\n",
       "      <td>0.048132</td>\n",
       "      <td>0.006675</td>\n",
       "      <td>-0.027617</td>\n",
       "      <td>-0.066860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/c/ga/iondúil</th>\n",
       "      <td>1.075489e-17</td>\n",
       "      <td>-7.396627e-07</td>\n",
       "      <td>-7.441649e-07</td>\n",
       "      <td>3.864260e-07</td>\n",
       "      <td>-1.202492e-16</td>\n",
       "      <td>-1.132471e-17</td>\n",
       "      <td>7.708410e-18</td>\n",
       "      <td>-4.189398e-17</td>\n",
       "      <td>-9.059036e-17</td>\n",
       "      <td>-8.593039e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029731</td>\n",
       "      <td>0.053838</td>\n",
       "      <td>0.033407</td>\n",
       "      <td>0.062806</td>\n",
       "      <td>0.034938</td>\n",
       "      <td>-0.049869</td>\n",
       "      <td>0.052862</td>\n",
       "      <td>-0.041310</td>\n",
       "      <td>0.003734</td>\n",
       "      <td>-0.074966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/c/gl/ler</th>\n",
       "      <td>9.624583e-17</td>\n",
       "      <td>-2.845818e-06</td>\n",
       "      <td>-8.588077e-07</td>\n",
       "      <td>2.685360e-07</td>\n",
       "      <td>4.596128e-16</td>\n",
       "      <td>-2.523832e-16</td>\n",
       "      <td>-4.270765e-16</td>\n",
       "      <td>-8.168780e-17</td>\n",
       "      <td>-8.408516e-17</td>\n",
       "      <td>7.169426e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034329</td>\n",
       "      <td>-0.019947</td>\n",
       "      <td>0.031885</td>\n",
       "      <td>0.107254</td>\n",
       "      <td>0.026175</td>\n",
       "      <td>-0.049850</td>\n",
       "      <td>0.053438</td>\n",
       "      <td>0.014593</td>\n",
       "      <td>-0.030902</td>\n",
       "      <td>-0.086152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/c/de/schieben</th>\n",
       "      <td>-9.004515e-17</td>\n",
       "      <td>-1.810347e-07</td>\n",
       "      <td>1.314632e-06</td>\n",
       "      <td>-7.960571e-07</td>\n",
       "      <td>7.706738e-17</td>\n",
       "      <td>1.748083e-17</td>\n",
       "      <td>-9.435811e-17</td>\n",
       "      <td>4.441733e-17</td>\n",
       "      <td>1.606452e-16</td>\n",
       "      <td>-6.052502e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033939</td>\n",
       "      <td>0.017956</td>\n",
       "      <td>0.041299</td>\n",
       "      <td>0.156516</td>\n",
       "      <td>0.023907</td>\n",
       "      <td>-0.011715</td>\n",
       "      <td>0.053101</td>\n",
       "      <td>-0.040555</td>\n",
       "      <td>-0.059441</td>\n",
       "      <td>-0.095432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/c/enm/teme</th>\n",
       "      <td>7.016783e-17</td>\n",
       "      <td>1.623994e-06</td>\n",
       "      <td>-1.047271e-06</td>\n",
       "      <td>1.852308e-06</td>\n",
       "      <td>-8.741855e-16</td>\n",
       "      <td>6.423836e-16</td>\n",
       "      <td>7.569734e-16</td>\n",
       "      <td>7.656732e-16</td>\n",
       "      <td>-9.475655e-17</td>\n",
       "      <td>3.190124e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027047</td>\n",
       "      <td>-0.016603</td>\n",
       "      <td>0.017813</td>\n",
       "      <td>0.080133</td>\n",
       "      <td>0.026272</td>\n",
       "      <td>-0.048739</td>\n",
       "      <td>0.054882</td>\n",
       "      <td>-0.035379</td>\n",
       "      <td>-0.055348</td>\n",
       "      <td>-0.022302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/c/pt/fragmento</th>\n",
       "      <td>4.829102e-17</td>\n",
       "      <td>5.132485e-05</td>\n",
       "      <td>-1.301653e-05</td>\n",
       "      <td>2.417272e-05</td>\n",
       "      <td>-1.563875e-14</td>\n",
       "      <td>9.338159e-15</td>\n",
       "      <td>1.298411e-14</td>\n",
       "      <td>6.888228e-15</td>\n",
       "      <td>-1.575646e-15</td>\n",
       "      <td>1.279317e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036802</td>\n",
       "      <td>-0.022231</td>\n",
       "      <td>0.040601</td>\n",
       "      <td>-0.029773</td>\n",
       "      <td>0.052640</td>\n",
       "      <td>-0.071455</td>\n",
       "      <td>0.068558</td>\n",
       "      <td>-0.028323</td>\n",
       "      <td>-0.127860</td>\n",
       "      <td>0.118185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/c/es/pelar</th>\n",
       "      <td>5.807841e-15</td>\n",
       "      <td>-1.675203e-03</td>\n",
       "      <td>1.116525e-02</td>\n",
       "      <td>3.552306e-02</td>\n",
       "      <td>-1.312445e-12</td>\n",
       "      <td>3.967632e-12</td>\n",
       "      <td>2.394475e-12</td>\n",
       "      <td>7.501550e-13</td>\n",
       "      <td>4.961104e-13</td>\n",
       "      <td>-2.075322e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035928</td>\n",
       "      <td>-0.029166</td>\n",
       "      <td>0.039210</td>\n",
       "      <td>-0.039801</td>\n",
       "      <td>-0.055165</td>\n",
       "      <td>-0.011612</td>\n",
       "      <td>0.053780</td>\n",
       "      <td>-0.001418</td>\n",
       "      <td>-0.064533</td>\n",
       "      <td>-0.089865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71949 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0             1             2             3    \\\n",
       "/c/de/verflechten  1.165642e-16 -1.401300e-06 -1.964500e-07  1.257201e-07   \n",
       "/c/gd/tost_geal    1.987298e-16  3.377577e-05 -1.186720e-05  1.642879e-05   \n",
       "/c/ru/осторожный  -6.373484e-17 -7.143095e-07  2.947653e-06  7.169659e-07   \n",
       "/c/tr/acil         8.302191e-17  4.772473e-06  4.615884e-06 -2.601526e-07   \n",
       "/c/ga/iondúil      1.075489e-17 -7.396627e-07 -7.441649e-07  3.864260e-07   \n",
       "...                         ...           ...           ...           ...   \n",
       "/c/gl/ler          9.624583e-17 -2.845818e-06 -8.588077e-07  2.685360e-07   \n",
       "/c/de/schieben    -9.004515e-17 -1.810347e-07  1.314632e-06 -7.960571e-07   \n",
       "/c/enm/teme        7.016783e-17  1.623994e-06 -1.047271e-06  1.852308e-06   \n",
       "/c/pt/fragmento    4.829102e-17  5.132485e-05 -1.301653e-05  2.417272e-05   \n",
       "/c/es/pelar        5.807841e-15 -1.675203e-03  1.116525e-02  3.552306e-02   \n",
       "\n",
       "                            4             5             6             7    \\\n",
       "/c/de/verflechten  1.929672e-16 -1.420060e-16 -1.816806e-16 -9.991165e-18   \n",
       "/c/gd/tost_geal   -7.791531e-15  5.764029e-15  6.711658e-15  7.940348e-15   \n",
       "/c/ru/осторожный   3.828752e-16 -4.195293e-17 -2.410384e-16 -5.321990e-16   \n",
       "/c/tr/acil        -2.876905e-15  1.288548e-15  2.358437e-15 -9.990318e-16   \n",
       "/c/ga/iondúil     -1.202492e-16 -1.132471e-17  7.708410e-18 -4.189398e-17   \n",
       "...                         ...           ...           ...           ...   \n",
       "/c/gl/ler          4.596128e-16 -2.523832e-16 -4.270765e-16 -8.168780e-17   \n",
       "/c/de/schieben     7.706738e-17  1.748083e-17 -9.435811e-17  4.441733e-17   \n",
       "/c/enm/teme       -8.741855e-16  6.423836e-16  7.569734e-16  7.656732e-16   \n",
       "/c/pt/fragmento   -1.563875e-14  9.338159e-15  1.298411e-14  6.888228e-15   \n",
       "/c/es/pelar       -1.312445e-12  3.967632e-12  2.394475e-12  7.501550e-13   \n",
       "\n",
       "                            8             9    ...       290       291  \\\n",
       "/c/de/verflechten  7.599815e-18  6.863060e-17  ...  0.030874 -0.029182   \n",
       "/c/gd/tost_geal   -1.166029e-15  3.713360e-15  ... -0.051047 -0.042544   \n",
       "/c/ru/осторожный   3.760020e-16 -5.890107e-16  ... -0.004821 -0.034773   \n",
       "/c/tr/acil         4.368428e-16 -1.655957e-15  ...  0.031403  0.003131   \n",
       "/c/ga/iondúil     -9.059036e-17 -8.593039e-17  ...  0.029731  0.053838   \n",
       "...                         ...           ...  ...       ...       ...   \n",
       "/c/gl/ler         -8.408516e-17  7.169426e-17  ...  0.034329 -0.019947   \n",
       "/c/de/schieben     1.606452e-16 -6.052502e-17  ...  0.033939  0.017956   \n",
       "/c/enm/teme       -9.475655e-17  3.190124e-16  ...  0.027047 -0.016603   \n",
       "/c/pt/fragmento   -1.575646e-15  1.279317e-15  ...  0.036802 -0.022231   \n",
       "/c/es/pelar        4.961104e-13 -2.075322e-12  ...  0.035928 -0.029166   \n",
       "\n",
       "                        292       293       294       295       296       297  \\\n",
       "/c/de/verflechten  0.022136 -0.040591  0.045733 -0.055873  0.054786 -0.048652   \n",
       "/c/gd/tost_geal    0.031218  0.114923  0.018571 -0.042055  0.052759 -0.043115   \n",
       "/c/ru/осторожный   0.035106  0.027656  0.046567 -0.000695  0.053960  0.195646   \n",
       "/c/tr/acil         0.033343  0.048443  0.039941 -0.045000  0.048132  0.006675   \n",
       "/c/ga/iondúil      0.033407  0.062806  0.034938 -0.049869  0.052862 -0.041310   \n",
       "...                     ...       ...       ...       ...       ...       ...   \n",
       "/c/gl/ler          0.031885  0.107254  0.026175 -0.049850  0.053438  0.014593   \n",
       "/c/de/schieben     0.041299  0.156516  0.023907 -0.011715  0.053101 -0.040555   \n",
       "/c/enm/teme        0.017813  0.080133  0.026272 -0.048739  0.054882 -0.035379   \n",
       "/c/pt/fragmento    0.040601 -0.029773  0.052640 -0.071455  0.068558 -0.028323   \n",
       "/c/es/pelar        0.039210 -0.039801 -0.055165 -0.011612  0.053780 -0.001418   \n",
       "\n",
       "                        298       299  \n",
       "/c/de/verflechten -0.064684 -0.101985  \n",
       "/c/gd/tost_geal   -0.061147 -0.036493  \n",
       "/c/ru/осторожный  -0.041995 -0.098684  \n",
       "/c/tr/acil        -0.027617 -0.066860  \n",
       "/c/ga/iondúil      0.003734 -0.074966  \n",
       "...                     ...       ...  \n",
       "/c/gl/ler         -0.030902 -0.086152  \n",
       "/c/de/schieben    -0.059441 -0.095432  \n",
       "/c/enm/teme       -0.055348 -0.022302  \n",
       "/c/pt/fragmento   -0.127860  0.118185  \n",
       "/c/es/pelar       -0.064533 -0.089865  \n",
       "\n",
       "[71949 rows x 300 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff1 = pd.concat([result, embedding]).drop_duplicates(keep=False)\n",
    "diff1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('test_propagate.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
